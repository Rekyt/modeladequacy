\documentclass[a4paper,12pt]{article}
\usepackage[osf]{mathpazo}
\usepackage{ms}
\usepackage{natbib}
\usepackage{lineno}
\usepackage{graphicx}
\usepackage{caption}
\modulolinenumbers[5]
\linenumbers

\pdfminorversion=3

\makeatletter
\renewcommand{\@biblabel}[1]{\quad#1.}
\makeatother

\title{On the adequacy of phylogenetic trait models}
\author{
Matthew W. Pennell$^{1, *}$, Richard G. FitzJohn$^2$,\\
William K. Cornwell$^{3}$ \& Luke J. Harmon$^1$
}

\date{}
\affiliation{
 $^{1}$ Department of Biological Sciences \& Institute for Bioinformatics and Evolutionary Studies, University of Idaho, Moscow, ID 83844, U.S.A.\\
 $^{2}$ Department of Biological Sciences, Macquarie University, Sydney, NSW 2109, Australia\\
 $^{3}$ School of Biological, Earth and Environmental Sciences, University of New South Wales, Sydney, NSW 2052, Australia\\
 $^{*}$ Email for correspondence: \texttt{mwpennell@gmail.com}
}

\runninghead{are macroevolutionary models adequate?}


\begin{document}

\mstitlepage
\parindent=1.5em
\addtolength{\parskip}{.3em}
\vfill


\begin{abstract}
\singlespacing
Investigating evolutionary hypotheses about the tempo and mode of evolution using interspecific data requires a statistical model that describes the mode of trait evolution through time. A wide variety of such models have been proposed, all of which make necessary simplifying assumptions.  Testing the fit of these models to data is now a routine component of comparative studies. However, an often over--looked statistical question is whether commonly-used models capture the relevant variation in traits. A model may be the best fit  relative to a set of candidate models (using some model selection criterion) but it may still be a poor fit in an absolute sense. However, we lack methods to assess fit in an absolute sense.  Here we develop a general framework for assessing the fit (or, adequacy) of quantitative trait models, based on Felsenstein's Independent Contrasts method. Our framework can be applied to arbitrarily complex trait models for which the tip values are assumed to multivariate normally distributed. We then use this approach to assess whether simple models are reasonable descriptors of the macroevolutionary dynamics of three important angiosperm functional traits: seed size, specific leaf area, and nitrogen content. We analyzed 1xx comparative datasets across the angiosperm phylogeny and demonstrate that there is tremendous variability in the adequacy of simple models across groups, traits and time--scales. We argue that the assessment of model adequacy should be included in all comparative studies and that the approach we present can be generally applied to this end.
\end{abstract}

\vfill

\newpage
\doublespacing


\begin{quotation}
\noindent There are known knowns; there are things we know we don't know. There are known unknowns; that is to say, there are things that we now know we don't know. But there are also unknown unknowns --- there are things we do not know we don't know.

---Fmr. U.S. Secretary of Defense Donald Rumsfeld
\end{quotation}


\noindent Model checking is a routine step in many statistical applications \citep[e.g.][ch. 6]{Gelmanbook}. Prior to drawing inferences from the parameters of a model, we want to know whether the model we used was any good. And not just whether it was the best of a set of candidates models, but whether it is a reasonable model in an absolute sense; this is referred to as goodness--of--fit or, model adequacy. While the importance of assessing the adequacy of our models is largely self--evident --- even the best of a set of bad models is still a bad model --- it has received relatively little consideration in phylogenetic comparative biology. Modern phylogenetic comparative methods (pcms) are almost exclusively model--based \citep[recently reviewed in][]{Omeara2012, PennellHarmon}. Whether we want to ask whether two traits are evolutionary correlated \citep[e.g.][]{Felsenstein1985, Grafen1989, HarveyPagel1991}, what the general pattern of trait evolution has been through a group's history \citep[e.g.][]{Mooers1999, Harmon2010, Hunt2012} or what features an ancestor may have had \citep[e.g.][]{Schluter1997, Huelsenbeck2003}, we need a statistical model which describes the pattern of trait evolution across the phylogeny. While many models for trait change and (increasingly sophisticated) methods for fitting them have been developed, we generally have very little idea as to whether the model we are using for a particular inference is adequate. What is worse is that it is often not even any thought when pcms are applied. To borrow Rumsfeld's taxonomy, it has largely been an ``unknown unknown''.

Modeling trait evolution along a phylogeny is certainly a challenging task and it has received less attention than the analogous problem of modeling the evolution of genetic sequences. For one thing, we generally are considering far less data when examining phenotypic traits compared to genetic data; for example, we probably only have a few  measurements of body size for each taxa in our phylogeny (if that!) whereas we may have thousands (or millions) of observations of genetic data for the same. Furthermore, while there is at least some mechanistic reasons why we might expect sequences to evolve in a certain way \citep{Kimura1983, Wakeley2008}, the trajectory of phenotypic evolution is likely to be very complex --- body size evolution within lineages of a group have almost certainly been subject to a myriad of selective (and non--selective) pressures throughout their histories. Nonetheless, it may be the case that the pattern of phenotypic evolution can be captured by relatively simplistic models; even if most of the details are missing, such models may be useful for quantiatively addressing macroevolutionary hypotheses. 

Brownian motion is the simplest, oldest, and most used, of such models in phylogenetic biology  \citep[BM;][]{Edwards1964, Felsenstein1973, Thompson1975}. In a BM model, the variance of a trait is assumed to accumulate linearly through time at some constant rate (usually denoted $\sigma^2$). Such a pattern may result from either genetic drift \citep{Lande1976, HansenMartins1996}, randomly varying selection \citep{Felsenstein1973, Felsenstein1988} or else simply reflect the summation of many processes operating over macroevolutionary time \citep{HansenMartins1996, Uyeda2011, PennellHarmon, PennellPE}. Whatever, the mechanism, BM has proven to be an extremely useful model in comparative biology; it is the probabilistic model underlying Felsenstein's Independent Contrasts method \citep[][see below]{Felsenstein1985} and is generally considered the null model against which all other models are compared \citep{Blomberg2003}. %WKC: Original math for BM was Einstein (1956, Investigations of the Theory of Brownian Movement ).  Interestingly it's only an analog, even for  molecules moving in a liquid; it's just represents a very simple continuous-time stochastic process.  It just turns out to have a lot of nice features mathematically and to be an adequate model for molecules moving in a liquid, not first-principle physics.  
Another model of quantitative trait evolution is the Ornstein--Uhlenbeck process \citep[OU;][]{Felsenstein1988, Hansen1997}, which can (very) loosely be described as ``evolution on a spring''. Under an OU model, variance accumulates at a rate $\sigma^2$, but is ``pulled'' towards a mean value $\theta$ with some strength $\alpha$ (this is mathematically equivalent to the case of stabilizing selection on a quantitative trait within a population \citep{Lande1976}). %WKC: but for all alphas estimated at this scale the time scale is all wrong, so at least we should mention the time-scale mis-match.  
Alternate models that have been considered include: the ``Early Burst'' \citep[EB;][]{Blomberg2003, Harmon2010, SlaterPennell} model, in which most of the evolution occurs early in the clades history; a BM model with a trend in the mean trait value \citep{Hunt2006}; models depicting jumps in phenotypic space \citep{Landis2012, Eastmanlevy}; and other variations on the models described above \citep[e.g.][]{Pagel1997, Pagel1999, ButlerKing2004, Omeara2006, Eastman2011, Beaulieu2012, SlaterMEE}. 

Comparative biologists may use these models in a number of different ways \citep{Freckleton2011, PennellHarmon}; the fit of the model may be used directly to make inferences regarding the ``tempo and mode'' of trait evolution \citep{HansenMartins1996, Mooers1999, Harmon2010} or else may be used to make secondary inferences, such as estimating the evolutionary correlation between traits \citep{Felsenstein1985}. In either case, it is important to consider the adequacy of the model that is used. For example, in the former application, if the ``true'' model of trait change resembles a multi--rate BM process \citep{Omeara2006, Thomas2006, Eastman2011} but we only consider BM and OU as alternative models, we might infer that an OU model is the best--fit, but would be completely misled regarding what processes were important in the evolution of the group. In the latter application, using an inadequate model would artificially decrease the confidence intervals around the estimate of the relationship between the traits in much the same way that neglecting the phylogeny altogether would \citep{Rohlf2001}. The question of model adequacy is even more pertinent as the scale of comparative data continues to grow. Comparative analyses are increasingly being performed on very large datasets including thousands and even tens of thousands of species \citep[e.g.][]{Coopermammal, Jetz2012, Rabosky2013, Cornwell2013, PyronBurbrink2013, Zanne2013}. While a simple model of trait evolution may suffice for a small clade of closely related organisms (e.g. seed size across Oak species), it seems unlikely that this would be true at much broader scales (e.g. seed size across all Angiosperms). 

There has been substantial investigation and discussion of model adequacy in the context of phylogenetic inference \citep[e.g.][]{GautLewis1995, SullivanSwofford, Goldman, HuelsenbeckBull1996, SandersonKim, Bollback2002, Ripplinger2010, Lewis2013, Brown2013} and it forms the basis for the Decision--Theoretic approach to model selection \citep{Minin2003, SullivanJoyce2005}. Contrastly, in phylogenetic comparative biology, researchers are just starting to begin to think about ways to assess model adequacy, especially for models more complex that a simple BM process. We note however, that despite the paucity of approaches, there has historically been a lot of discussion surrounding the appropriateness of various models for pcms, particularly in the pioneering days of the field \citep[e.g.][]{Felsenstein1985, Felsenstein1988, HarveyPagel1991, Pagel1993, Diaz1996, Price1997, GarlandIves2000, Hansen2012} and our own approach draws heavy inspiration from these earlier work.

Recently, two papers have developed simulation--based approaches to assessing the fit of models. \citet{Boettiger2012} developed a ``phylogenetic monte carlo'' approach to assess when a given comparative data set contained enough information to distinguish between two candidate models. In brief, their procedure was as follows: 1) select 2 candidate models $\mathcal{M}_0$ and $\mathcal{M}_1$; 2) fit $\mathcal{M}_0$ and $\mathcal{M}_1$ to the data using Maximum likelihood; 3) use the MLE for model parameters $\hat{\Theta}$ to simulate $n$ data sets; 4) for each of the $n$ data sets simulated under $\mathcal{M}_0$, fit both $\mathcal{M}_0$ and $\mathcal{M}_1$ and calculate difference in likelihood values $\delta = -2(L_{\mathcal{M}_0} - L_{\mathcal{M}_1})$; and 5) compare distribution of $\delta$ for datasets simulated under $\mathcal{M}_0$ with distribution of $\delta$ for datasets simulated under $\mathcal{M}_1$. \citet{Boettiger2012} demonstrated that their approach had much better ``classical'' statistical properties (specifically Type--I and Type--II errors) compared to using Information Theoretic methods of model selection, such as AIC \citep{Akaike1974}, AICc \citep{AICC}, and BIC \citep{Schwarz1978}. (Though we note that this is not an entirely fair comparison; Information Theoretic approaches differ philosophically from frequentist approaches to model selection  and do not have Type--I and Type--II error rates in the same way likelihood ratio tests \citep{Wilkes1938} are expected to have.)

In the other paper, \citet{SlaterPennell} also focused on the case of comparing two--models. Their method differs from that of \citet{Boettiger2012} in that theirs was a fully Bayesian posterior predictive approach specifically aimed at detecting ``early bursts'' of trait evolution \citep[\textit{sensu}][]{Simpson1944, Harmon2010}. They estimated the posterior distribution of parameters for a candidate model (here either BM or EB), then sampled parameter values from the joint posterior distribution. They then simulated data under the sampled parameters and then used two alternative summary statistics --- the relationship between the logarithm of the phylogenetic independent contrasts and the height above the root that the contrasts was inferred \citep[a.k.a. the ``node height test'';][]{FreckletonHarvey2006}, and the Mean Disparity Index \citep[MDI;][]{Harmon2003, Slater2010} --- to evaluate whether the observed summary statistics were consistent with the summary statistics computed on the simulated datasets and thus decide whether the model was adequate. They showed that conducting this procedure on both BM and EB models was more powerful and reliable in distinguishing an early burst of trait evolution compared to more conventional approaches.

However, both of these cases used a simulation based approach to assess whether the data was informative enough to select amongst two candidate models. A broader question is whether a given model is a good fit to the data on its own terms --- that is, compared to the universe of possible models we could consider. Here we develop a approach to statistically evaluate absolute goodness--of--fit for models of continuous character evolution. The basic idea of our approach is rather simple. If we have a trait that has evolved on the phylogeny via a BM process with a rate ($\sigma^2$) equal to 1, the contrasts \citep[\textit{sensu}][see below]{Felsenstein1985} will be independent and identically distributed (I.I.D.) according to a standard normal distribution $\mathcal{N}(0,1)$. In our approach, we first rescale the phylogeny according to the model fit, such that if the model were the generating model, the trait data would be distributed as it would be under a BM process with a rate of 1 (which we will refer to as a ``unit tree''). We then calculate the contrasts at each node and compute a set of summary statistics, which capture different aspects of the variance. We then simulate datasets under BM (again, using $\sigma^2 = 1$) and calculate our summary statistics on each simulated dataset. We can then compare our observed to our simulated summary statistics (details below), allowing us to evaluate whether our model we have chosen is indeed an adequate one.

We then use our approach to evaluate the ability of simple models to describe the evolution of functional traits in Angiosperms at a number of different scales. Angiosperms are one of the most spectacular radiations in the history of the earth. The $>$300,000 species which make up the clade have diversified into a huge array of functional forms, from the grasses of the Serengeti to the trees of the Amazonian rainforest, and have come to dominate most terrestrial ecosystems.

%% PARAGRAPH: THESE ARE THE QUESTIONS WE WANT TO ADDRESS WITH THIS DATA.
%% not sure exactly what to do here.
As researchers interested in macroevolution, we would like to understand how such trait diversity came to be --- the who, what, when, where and whys of deep time. For example, seed size is associated with many other life--history triats [give example] and varies $\sim$ 11 orders of magnitude across extant angiosperm species \citep{Westoby1992TREE, Moles2005}. [Talk about other things we know about seed size; cite Lord 1995, Westoby 2002, Moles 2005, Cornwell 2013, etc.]


\section*{A framework for assessing model adequacy}

Our approach is based on the use of Felsenstein's \citep{Felsenstein1973, Felsenstein1985} Phylogenetic Independent Contrasts (PIC) method, which we will briefly review \citep[for more details, see][]{Felsenstein1985, Rohlf2001, Blomberg2012}. We have observed trait values $X_1, X_2, \ldots, X_n$ at the tips of a phylogenetic tree $\mathcal{T}$ consisting of $n$ species. Due to shared history of ancestry between the tips, $X_1, X_2, \ldots, X_n$ are not independent observations. To deal with this problem, Felsenstein suggested taking $n-1$ contrasts $c_1, c_2, \ldots, c_{n-1}$, the differences $X_{i} - X_{j}$ between the observations at tips $i$ and $j$. If we assume a BM model of trait evolution, in which variation accumulates directly proportional to time, these contrasts will be independent and identically distributed (I.I.D.) --- hence the name, ``PICs''. The procedure can be described algorithmically: 1) Take the contrast $c = X_i - X_j$ at node $k$, where $k$ is the most recent common ancestor of tips $i$ and $j$. 2) Standardize the contrast by its dividing by its standard deviation, which under BM is $\sqrt{v_i + v_j}$, the square root of the sum of the branch lengths leading to $i$ and $j$, 3) Estimate a trait value for the ancestral node $k$ by taking the mean of its descendants' trait values, weighted by their branch lengths

\begin{equation}
X_k = \frac{(1 / v_i)X_i + (1 / v_j)X_j}{1/v_i + 1/v_j}.
\end{equation}

4) Lengthen the branch below $k$ by $v_i v_j / (v_i + v_j)$, in order to account for error in the estimation of $k$. Iterating across all nodes in the phylogeny, the result is a set of contrasts $\mathbf{c}$, which, as stated above, will be I.I.D. \textit{only if the model which generated the observations was BM} \citep{Rohlf2001}. As our method described in this paper essentially evaluates whether this condition holds, we will refer to $\mathbf{c}$ as contrasts, rather than PICs throughout.

The basic principle of our approach is straightforward. Given a set of $n$ observations, we can compute the $n-1$ contrasts. We calculate a set of summary statistics on the ``observed'' contrasts $\mathcal{S}^*$. We then simulate $N$ datasets using a Brownian motion model of trait evolution, compute the contrasts on each data set and calculate the same summary statistics $\mathcal{S}$. We then compare $\mathcal{S}^*$ to $\mathcal{S}$. If $\mathcal{S}^*$ lies in the tails of $\mathcal{S}$, our model is not capturing variation along a relevant axis.

\subsection*{Summary statistics}

To assess model adequacy we have chosen 6 summary statistics $\mathcal{S} = \lbrace \mathcal{S}_1, \ldots, \mathcal{S}_6 \rbrace$

\begin{enumerate}
\item[$\mathcal{S}_1$] The mean of the squared contrasts. This is equivalent to the Restricted maximum likelihood (REML) estimate of the Brownian motion rate parameter $\sigma^2$ \citep{Garland1992, Rohlf2001}. We chose this statistic to detect misestimation of the BM rate parameter.

\item[$\mathcal{S}_2$] The variance in the absolute value of the contrasts. We used this statistic to detect heterogeneity in the rate of trait evolution \citep[\textit{sensu}][]{Omeara2006, Eastman2011}.

\item[$\mathcal{S}_3$] The slope resulting from fitting a linear model between the absolute value of the contrasts and their expected variances. Each contrast has an expected variance of XX \citep{Felsenstein1985}. Under a model of BM, we expect no relationship between these. In using this, we are asking whether the contrasts are larger or smaller than we expect based on their branch lengths. If, for example, more evolution occured per unit time on short branches than long branches, we would observe a negative slope.

\item[$\mathcal{S}_4$] The slope resulting from fitting a linear model between the absolute value of the PICs and the inferred ancestral state. We estimated the ancestral state using the least--squared method suggested by \citep{Felsenstein1985} for the calculation of contrasts. We note that this is not technically an ancestral state reconstruction and differs from more commonly applied approaches \citep[such as the  maximum likelihood estimator][]{Schluter1997} in that it reconstructs the ancestral states node by node (such that the reconstructions are marginal rather than joint reconstructions) and that does not consider the error in any given estimate. While we do not suggest that this is a reliable method for ancestral state reconstruction, for our purposes it is advantagous in that it is internally consistent with the calculation of the states, such that we have a clear expectation that the test statistic will be 0 if the model is correct; it is also computationally fast, allowing us to quickly apply it to many simulations. We used this statistic to evaluate whether there is variation in rates relative to the trait value (e.g. do larger organisms evolve faster?)

\item[$\mathcal{S}_5$] The slope resulting from fitting a linear model between the absolute value of the contrasts and the height above the root at which they are inferred. This is alternatively known as the node height test \citep{FreckletonHarvey2006, SlaterPennell} for detecting early bursts of trait evolution and has been been previously used to assess the fit of BM models.

\item[$\mathcal{S}_6$] The D--statistic obtained from Kolmolgorov-Smirnov test from comparing the distribution of contrasts to that of a normal distribution with mean 0 and standard deviation $\sqrt{\overline{\mathbf{c}^2}}$ --- the expected distribution of the contrasts under BM \citep{Felsenstein1985, Rohlf2001}. We chose this to capture deviations from normality, such as would be produced if traits evolved via a ``jump diffusion'' type model \citep{Landis2012, Eastmanlevy}, in which trait evolution may occasionally occur at rates much greater than the background rates \citep[see][]{PennellPE}. We used the empirically estimated standard deviation, rather than the expected (i.e. $\sigma^2=1$) to make $\mathcal{S}_1$ and $\mathcal{S}_6$ more independent.

\end{enumerate}

The three summary statistics fitting a linear model between the contrasts and some aspect of the data (i.e. $\mathcal{S}_3, \mathcal{S}_4, \mathcal{S}_5$) were developed by Garland and colleagues \citep{Garland1992, Garland1993,  Diaz1996} to test for adequacy of BM prior to performing PICs \citep{Felsenstein1985} or phylogenetic regression \citep{Grafen1989}. They were implemented in the formerly popular program \texttt{PDAP} \citep{Garland1993, Midford2005} and have been well used in the comparative methods literature (at least until more recently).

We have chosen these statistics because they capture a range of dimensions of variability wherein the model may not be adequate. However, they are certainly not exhaustive. One could, for instance, calculate the median of the squared contrasts, the skew of the distribution of contrasts, etc. If the generating (i.e. ``true'') model was known, we could use established procedures for selecting a set of sufficient (or approximately sufficient) summary statistics \citep[e.g.][]{MajoramJoyce, Slater2012MECCA}. However, the aim of our project is to seek a set of summary statistics that capture violations of the assumption that the contrasts are I.I.D. and thus we do not have the generating model in hand. Our chosen statistics appear to capture a wide variety of model misspecifications (see below) but this does not mean that they will necessarily capture \textit{any} model misspecification. Researchers interested in specific questions are encouraged to try alternate sets of summary statistics; we have made the software implementation of our approach as flexible as possible to accomodate alternative sets of statistics. (We describe how users of our software can easily implement these in the Supplementary Materials.) We also note that a model will be considered inadequate if it is rejected by \textit{any} of the summary statistics that can be used. In principle, one could evaluate the model fit with a large number of summary statistics. Even if the model is not rejected by any of the summary statistics used, we still do not know if there adding another statistic would cause us to reject the model. This is perhaps a somewhat unsatisfying situation to be in but we have to learn to live with it. The choice of how many summary statistics to use is ultimately one of balancing statistical intuition and computational effort.

\subsection*{Rescaling the phylogeny}

While the above summary statistics are appropriate for a BM model of trait evolution, the same will not be true of alternative models. That is because under alternative models, we no longer expect the contrasts to have I.I.D. properties. Our solution to the problem is to use the estimated parameters of a more complex model $\Theta$ to create what we term a ``unit tree''. A unit tree is defined as a tree in which if the model we fit is the generating model, the data at the tips will be distributed as it would be under a BM process with a rate $\sigma^2$ equal to 1. Any phylogenetic tree $\mathcal{T}$ can be completely described by a $n \times n$ variance--covariance (vcv) matrix $\mathbf{C}$, where $n$ is equal to the number of tips in $\mathcal{T}$. The elements $C_{i,j}$ are the shared path--length from the root to the most recent common ancestor of $i$ and $j$ \citep{Piazza1975}. The diagonal elements ($i = j$) are simply the total distance from the root to the tips. For any model, we can describe a second matrix $\mathbf{\Sigma}$, which is the expected vcv matrix between observations at the tips. For example, under BM, in which variation accumulates proportionally to time under a single rate $\sigma^2$,
\begin{equation}
\Sigma_{ij} = \sigma^2 C_{ij}
\end{equation}
and thus
\begin{equation}
\mathbf{\Sigma} = \sigma^2 \mathbf{C}.
\end{equation}
We can similarily construct $\mathbf{\Sigma}$ based on whatever model we are interested in. \citet{HoAne2013} describe a condition which they refer to as the ``3 point condition''; a vcv matrix $\mathbf{\Sigma}$ satisfies this condition if, and only if, it is symmetric, has only non--negative entries and that for any $i,j,k$, the two smallest of $\Sigma_{i,j}, \Sigma_{j,k}, \Sigma_{i,k}$ are equal. They prove that a) this condition is only met for rooted phylogenies with trait data generated under BM; and b) that any $\mathbf{\Sigma}$ based on a multivariate Gaussian distribution can be rescaled to satisfy the condition. Our concept of a unit tree is equivalent to their ``3 point condition'' which the additional requirement that rate parameter of the BM model is equal to 1. This last requirement puts all models on the same scale so that it is more intutive to compare them; however, this is not strictly necessary. As stated above, a unit tree can be constructed from any multivariate Gaussian model such as mulit--rate BM \citep{Omeara2006, Thomas2006, Eastman2011, Revell2012, Motmot}, Pagel's $\lambda$, $\kappa$, and $\delta$ transformations \citep{Pagel1997, Pagel1999}, the AC/DC model \citep{Blomberg2003} \citep[a.k.a. `EB';][]{Harmon2010, SlaterPennell}, models with a directional trend \citep{Hunt2007} and others \citep[e.g.][]{SlaterMEE}. OU models can also be rescaled to form a unit tree; this is true of both multi--optimum \citep{ButlerKing2004} models and the more generalized form \citep{Beaulieu2012, IngramMahler, UyedaBayou} in which the optimum, $\sigma^2$ and $\alpha$ values all vary across the tree \citep{HoAne2013}. We note that all of above applies to both ultrametric and non--ultrametric phylogenies \citep{HoAne2013}, such that the methods we describe can be applied to trees consisting of fossil taxa as well.

The approach we describe is applicable to univariate and additionally to multivariate analyses, such as ``phylogenetic regression'' (e.g. ``phylogenetic generalized least squares''; PGLS) analyses, in which the aim is to test for evolutionary correlations between traits \citep{Grafen1989, Rohlf2001}. In general terms, we can write down the regression equation as:

\begin{equation}
\mathbf{y} = \mathbf{b}\mathbf{X} + \epsilon .
\end{equation}

Here $\mathbf{y}$ is the $n \times 1$ vector of the dependent variable, $\mathbf{b}$ is the vector of partial regression coefficients, $\mathbf{X}$ is the $n \times q$ matrix of independent variables ($q$ being the number of traits included in the model) and $\epsilon$ is the error term. In ordinary least squared (OLS) regression, we assume that the error term $\epsilon$ is normally distributed with parameters $(0, \sigma^2)$. However, when we taken into account the covariation between tip observation due to the pattern of shared ancestry, the residuals are no longer I.I.D. and will be distributed $\mathcal{N} (0, \mathbf{\Sigma})$, where again $\mathbf{\Sigma}$ is the estimated vcv matrix from fitting the evolutinary model. While the original version of PGLS assumed a BM model of trait evolution, this has been expanded to include a number of models, including the $\lambda$ model \citep{Pagel1997, Revell2010, Freckleton2011} and OU \citep[e.g.][]{Hansen2008} among others \citep[see also][]{Lynch1991, Hadfield2010}. Similar to the univariate case described above, these regression equations fundamentally depend on the use of an appropriate model \citep{Hansen2012}. To assess the adequacy of the model used to estimate $\mathbf{\Sigma}$, we can use an identical approach to the one described above, but rather that take the contrasts of the trait values, we take the contrasts of the residuals from fitting our regression model to the data. This may not appear intuitive, but phylogenetic regression models do not apply the covariance matrix to the data themselves, only to the residuals; in other words, the phylogenetic structure of actual data does not matter, only that of the residuals \citep{Rohlf2001}. Therefore, if the model specifiying $\mathbf{\Sigma}$ is correct, the contrasts of the residuals taken along the unit tree will also be I.I.D. The GLS estimator for the  BM rate parameter $\hat{\sigma^2}$ of the residuals ($y = y_1, y_2, \ldots , y_N$) is equivalent to

\begin{equation}
\hat{\sigma^2} = \frac{(y - \hat{\alpha}\mathbf{X})^T \mathbf{C^{-1}} (y - \hat{\alpha}\mathbf{X})}{N-1} 
\end{equation}

\citep{GarlandIves2000, Freckleton2002}, where again $\mathbf{C}$ is the vcv matrix describing the phylogeny, $\hat{\alpha}$ is the estimated rooted state and $\mathbf{X}$ is a $n \times 1$ identity matrix. If the correlation structure is BM, then we can estimate $\sigma^2_{BM}$ directly from the residuals using the phylogeny. If some other correlation structure is used (such as a $\lambda$ transformation), we must first rescale $\mathbf{C}$ according to the estimated parameter, then use the transformed tree to estimate $\sigma^2_{BM}$. We note that while the approach presented here can be used to evaluate the adequacy of the trait model, it does not assess the adequacy of the linear component of the model $\mathbf{y} = \mathbf{b}\mathbf{X}$. It is also worth noting here that even if $\hat{\mathbf{\Sigma}}$ is misspecified, such as by using an incorrect model or an incorrect tree, the GLS estimate of the slope $\mathbf{b}$ will be unbiased \citep{Rao1999}; however the variance of the estimator will be too small \citep{Rohlf2006}. And where deviations from the true $\mathbf{b}$ do occur, the directions of the deviations (i.e. a higher or lower regression coefficient) are not necessarily predictable \citep{Rohlf2006}.

\subsection*{Posterior predictive simulations versus parametric bootstrapping}
There are two alternative ways to conceive of our method. From a Bayesian perspective, our approach can be considered as a form of posterior predictive check \citep{Rubin1984, Gelman1996, Gelmanbook}. In this case, we fit a model using Bayesian machinery (e.g. Markov chain Monte Carlo, MCMC, methods), then sample parameter values $\Theta$ from the joint posterior distribution. For each sampled parameter set $\Theta$, we rescale the original phylogeny to a unit tree, calculate a set of summary statistics $\mathcal{S}^*$ and then simulated a dataset on this rescaled tree. On each simulated dataset, we compute the summary statistics $\mathcal{S}$. We can then compare the distribution of summary statistics from the observed dataset to that of the simulated datasets. The one--tailed p-value is approximated by the number of times $\mathcal{S}^* < \mathcal{S}$ and the two--tailed test is simply 2 times the minimum of the number of simulations where $\mathcal{S}^* < \mathcal{S}$ and those where $\mathcal{S}^* > \mathcal{S}$.

Alternatively, one can employ our method in a frequentist framework. As such, our method can be construed as a parametric bootstrapping approach \citep{Efronbootstrap}. First, the maximum likelihood (or alternatively, REML, GLS, etc.) values of a set of model parameters $\hat{\Theta}$ are estimated. $\hat{\Theta}$ is used to  generate the unit tree. We calculate our set of summary statistics on our observed data $\mathcal{S}^*$. We then simulate \textit{n} datasets under a BM process with $\sigma^2 = 1$. On each simulated dataset we calculate our set of summary statistics $\mathcal{S}$. We then compare $\mathcal{S}^*$ to the distribution of $\mathcal{S}$. If any of our observed statistics lies in the tails of that of the simulated data, we conclude that our model is not accounting for variation along the axis captured by the summary statistic.


\section*{Two worked examples --- seed size evolution in the Meliaceae \& the Fagaceae}
To better illustrate our approach, we have selected two empirical datasets, both of which are subsets of our larger analyses of functional trait evolution in Angiosperms. We collected data on seed mass from the Kew online database \citep{Kew2008} and matched the trait data to the Meliaceae (common name) and Fagaceae (common name) subtrees pruned from a larger phylogeny \citep{Zanne2013}. After matching the available data, we had a comparative datasets consisting of 44 species for the Meliaceae and 70 species for the Fagaceae --- both fairly typically sized datasets.  Using the \texttt{R} package \texttt{geiger} \citep{geiger}, we used maximum likelihood to fit both a simple BM model and a simple OU model to the data. In both cases, an OU model was strongly supported; the AIC weight for the OU model was $\sim 0.99$ for both clades. One might be tempted to conclude from this that similar evolutionary processes were occuring in both groups. 

However, from the perspective of model adequacy, the story is very different (see \ref{family-example-fig}). For both clades and both models, we rescaled the phylogeny based on ML parameter estimates, calculated our six summary statistics on the rescaled phylogeny, then simulated 1000 datasets and calculated the summary statistics on each simulated dataset. For the Meliaceae, the OU model was indeed an adequate model; the observed summary statistics were in the middle of the distribution of simulated summary statistics ($\mathcal{S}_1: p=0.448$, $\mathcal{S}_2: p=0.803$, $\mathcal{S}_3: p=0.633$, $\mathcal{S}_4:p=0.496$, $\mathcal{S}_5: p=0.148$, $\mathcal{S}_6: p=0.629$). However, even though OU was highly supported, a BM model also adequately captured the variation in the data ($\mathcal{S}_1: p=0.272$, $\mathcal{S}_2: p=0.987$, $\mathcal{S}_3: p=0.380$, $\mathcal{S}_4:p=0.172$, $\mathcal{S}_5: p=0.360$, $\mathcal{S}_6: p=0.340$), suggesting that model selection via AIC was selecting an overparameterized model; this conclusion is consistent with the findings of \citet{Boettiger2012}. We found the exact opposite for the models fit to the Fagaceae data --- \textit{neither} OU nor BM were an adequate model for this group. The OU model was shown to be inadequate by both $\mathcal{S}_1$ ($p \sim 0$) and by $\mathcal{S}_2$ ($p=0.006)$; the rest of the observed summary statistics did not differ significantly from the simulated summary statistics ($\mathcal{S}_3: p=0.228$, $\mathcal{S}_4:p=0.364$, $\mathcal{S}_5: p=0.828$, $\mathcal{S}_6: p=0.955$). The BM model performed worse for all these statistics. These results suggest that the reason that the OU model is an inadequate model for the evolution of seed mass in the Fagaceae is that it is not accomodating variation in evolutionary rates across the tree --- both the overall rate $\mathcal{S}_1$ and variance in rate $\mathcal{S}_2$ were not well captured by this model. The reason the OU model was preferred over BM may having nothing at all to do with a ``clade optimum'' or ``stabilizing selection'' but rather the additional parameter may be just explaning some additional noise in the data. The next logical step if we were to pursue this would be to consider multi--rate or mulit--optimum models \citep[e.g.][]{Omeara2006, Eastman2011, Beaulieu2012, UyedaBayou}; however this is beyond the scope of this illustration.

\subsection*{Phylogenetic tree and Trait Data}
We used a phylogeny of Angiosperms from a recent study by \citet{Zanne2013}. The tree contains 31,749 land plant taxa and covers xx \% of familial diversity and yy \% of generic diversity across all Angiosperms. We will not provide the details on the phylogeny here and refer interested readers to the original publication \citep{Zanne2013}. For the purposes of this study, we used the MLE point estimate of the phylogeny. We could have used a set of bootstrapped trees and ran our analyses across all of them, but for our purposes, it should not qualitatively affect our results. This tree is published in \textsc{treebase} (assession number) and \textsc{dryad} (accession number).
%% Actually we could use a set of bootstrapped trees. No big problem. The only issue is that we would need to find some nice way of describing (and plotting) the results.

%% Information on data goes here. 
%% Will, I am leaving this for you to take a crack at.

We used large datasets on three important, continuous plant traits: specific leaf area, leaf nitrogen content, and seed mass.  All data are available via the web (see appendix for specific locations and scripts to access the original data). Specific leaf area (SLA) and leaf nitrogen data comes from \citet{Wright2004} with additional SLA data from the LEDA project \citep{Kleyer2008}.   Seed mass data comes Kew \citep{Kew2008}.  Geometric species means were used for all three traits.  The full data set includes 3369 species for SLA of which XX correspond to species in the \citet{Zanne2013} tree.  The sample size for leaf N is XX and YY; for seed mass it is ZZ and FF.  
%add Cornwell et al 2006?  http://ucjeps.berkeley.edu/efc/dbase.html

%INTRASPECIFIC VARIATION?

\subsection*{The adequacy of models for functional trait evolution in Angiosperms}

%% Describe:
%% what models we fit
%% how we fit them
%% how we compared models
%% the different scales we looked at

\section*{Results}

\subsection*{Simulation results}

\subsection*{Adequacy of models for plant functional traits}

\section*{Discussion}

The method we have described here can apply to any model of trait evolution which can be described by a multivariate normal distribution. That is, where the original tree can be transformed from the model fit to a unit tree. Our approach can therefore not be applied to other types of models, such as those which assume a long--tailed distribution of trait change \citep[e.g.][]{Landis2012} or state--dependent diversification models \citep[e.g.][]{Bokma2008, Bokma2010, FitzJohn2010}. And it is not applicable to models of discrete character evolution, such as the Mk model \citep{Pagel1994, Lewis2001} and variations thereof \citep[e.g.][]{Maddison2007, WagnerMarcot2010, Mazeralli2012, Beaulieu2013} \citep[but see Felsenstein's threshold model;][]{Felsenstein2005, Felsenstein2012}. Methods to evaluate the adequacy of discrete character models are also sorely needed as the issue is just as pertinent in this case \citep{ReadNee1995}, though the statistics involved will necessarily be different. Likewise, similar approaches could also be adopted for evaluating the adequacy of models of lineage diversification; some work has been done on this \citep[e.g.][]{Rabosky2009AmNat, Rabosky2012} but we do not yet have a general method for looking at this, especially for complex models of diversification \citep[e.g.][]{Stadler2011, Etienne2012}.

%% Paragraph on measurement error and other sources of error
Model misspecification is not the only source of error when fitting trait models. Estimating parameters (especially under ML) is often non--trivial owing to identifiability issues in regions of parameter space \citep{Ane2008, HoAne2012} --- these issues are generally underexplored but are likely to be pervasive; even more so for parameter--rich models. As the construction of the unit tree depends on the parameter estimates, our approach will be sensitive to their mis--estimation. Second, measurement error may have pathological effects regarding model adequacy \citep{HarmonLosos2005} and the effects may vary depending on the model used \citep{RevellReynolds2012, PennellPE}.


%% Paragraph on sampling bias
Another complication which has the potential to mislead inferences is based sampling of traits \citep{Freckletoninaction, FitzJohnwoody}. All the trait models considered in this study assume that evolution has occured independently on each branch, such that as long as the taxa included in the phylogeny are a more--or--less random sample, the parameter estimates should not be biased as a result \citep{PennellHarmon}. However, in many cases \citep[especially when using large trait databases;][]{FitzJohnwoody} this will not be the case. Importantly this will not be detected by the model adequacy approach presented in this paper: the bias in the parameter estimates will be systematically the same across all the simulated datasets.

We hope that our approach can help move model adequacy from being an ``unknown unknown''  to being a ``known known'' or at least a ``known unknown'' --- that is to say, we may not know exactly why our model is not capturing the variation in the data, but at least we will know it is not.


\section*{A note on implementation}

The method described here has been implemented in an R package \texttt{arbutus}. It is available on CRAN and at \texttt{www.github.com/mwpennell/arbutus}. For this project, we have also adopted code from the \texttt{ape} \citep{ape}, \texttt{geiger} \citep{geiger}, \texttt{diversitree} \citep{FitzJohn2012} and \texttt{ggplot2} \citep{ggplot2} libraries. We have written functions to parse the output of a number of different programs for fitting trait evolution models (see \ref{supp-table-fxns}). As this approach was developed to be general, we have written the code in such a way that users can include their own summary statistics and trait models in the analyses; we include demonstrations of how this can be done in the supplementary material.

\section*{Concluding remarks}

While we describe this as a novel approach, much of it stems directly from earlier work in the field. In the 1980s and 1990s --- the when phylogenetic comparative biology was just starting to emerge as a discipline --- much discussion surrounded the appropriateness of various methods and models [cite lots including some missteps, e.g. Westoby 1995]. However, as phylogenetic approaches have become more widely accepted and applied in a variety of fields, including community ecology \citep{Webb2002, CB2009, Mayfield2010, PennellHarmon}, paleobiology \citep{Hunt2012}, anthropology \citep{Nunnbook}, etc., much of this debate has seemingly been largely forgotten \citep[but see][]{Losos2011}. However, as the scale of phylogenetic comparative data has grown, these concerns regarding model adequacy are more pertinent than ever. We argue that evaluating the fit of macroevolutionary models ought to be an important component of any comparative analysis. The approach we develop in this paper can generally be applied to a variety of continuous trait models. Alternative approaches that can apply to discrete models (binary, multistate and ordinal) as well as continuous trait models which are not multivariate normal are needed. If nothing else, we hope that our article spurs renewed interest in understanding when models capture the information we are interested in. \citet[][p. 14]{Felsenstein1985} wrote that ``[p]hylogenies are fundamental to comparative biology; there is no doing it without taking them into account''. We agree, but would add that models are also fundamental to comparative biology and that there is no doing it without considering their adequacy.


\section*{Acknowledgments}

We would like to thank the members of the Tempo and Mode of Trait Evolution Working Group at the National Evolutionary Synthesis Center (NESCent) as well as NESCent for funding our group. Josef Uyeda, Jeremy Beaulieu and Daniel Caetano also provided insightful comments on this project. MWP was supported by a Bioinformatics and Computational Biology Graduate Fellowship from the University of Idaho and a NSERC post--graduate fellowship. LJH was supported by NSF (AVAToL ).



\newpage
\bibliographystyle{sysbio}
\bibliography{model_ad.bib}

\end{document}
