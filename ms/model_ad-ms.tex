\documentclass[a4paper,12pt]{article}
\usepackage[osf]{mathpazo}
\usepackage{ms}
\usepackage{natbib}
\usepackage{lineno}
\usepackage{graphicx}
\usepackage{caption}
\modulolinenumbers[5]
\linenumbers

\pdfminorversion=3

\makeatletter
\renewcommand{\@biblabel}[1]{\quad#1.}
\makeatother

\title{On the adequacy of phylogenetic trait models}
\author{
Matthew W. Pennell$^{1, *}$, Richard G. FitzJohn$^2$,\\
William K. Cornwell$^{3}$ \& Luke J. Harmon$^{1,4}$
}

\date{}
\affiliation{
 $^{1}$ Department of Biological Sciences \& Institute for Bioinformatics and Evolutionary Studies, University of Idaho, Moscow, ID 83844, U.S.A.\\ 
 $^{*}$ Email for correspondence: \texttt{mwpennell@gmail.com}\\
 $^{2}$ Department of Biological Sciences, Macquarie University, Sydney, NSW 2109, Australia;
\texttt{rich.fitzjohn@gmail.com}\\
 $^{3}$ School of Biological, Earth and Environmental Sciences, University of New South Wales, Sydney, NSW 2052, Australia; \texttt{w.cornwell@unsw.edu.au}\\
 $^{4}$ \texttt{lukeh@uidaho.edu}
}

\runninghead{are macroevolutionary models adequate?}
\keywords{comparative methods, model adequacy, independent contrasts, Brownian motion}


\begin{document}

\mstitlepage
\parindent=1.5em
\addtolength{\parskip}{.3em}
\vfill


\begin{abstract}
\singlespacing
Investigating evolutionary hypotheses using interspecific data requires both a phylogeny and a statistical model that describes the mode of trait evolution through time. A wide variety of such models have been proposed, all of which necessarily make simplifying assumptions. An often over--looked statistical question is whether the model used is actually capturing the relevant variation in traits. A model may be the best fit relative to a set of candidate models, using some model selection criterion, but it may still be a poor fit in an absolute sense; however, we lack methods to evaluate this. Here we develop a general framework for assessing the fit (or, adequacy) of quantitative trait models, based on Felsenstein's Independent Contrasts method. Our framework can be applied to arbitrarily complex trait models for which the tip values are assumed to distributed according to a multivariate normal distribution. We then use this approach to assess whether simple models are reasonable descriptors of the macroevolutionary dynamics of three important angiosperm functional traits: specific leaf area, seed mass and leaf nitrogen content. We analyzed 1xx comparative datasets across the angiosperm phylogeny and demonstrate that there is tremendous variability in the adequacy of simple models across groups, traits and time--scales. We argue that the assessment of model adequacy should be included in all comparative studies and that the approach we present can be applied generally to this end.
\end{abstract}

\vfill

\newpage
\doublespacing


\begin{quotation}
\noindent There are known knowns; there are things we know we don't know. There are known unknowns; that is to say, there are things that we now know we don't know. But there are also unknown unknowns --- there are things we do not know we don't know.

---Fmr. U.S. Secretary of Defense Donald Rumsfeld
\end{quotation}


\noindent Model checking is a routine step in many statistical applications \citep[e.g.][ch. 6]{Gelmanbook}. Prior to drawing inferences from the parameters of a model, we want to know whether the model we used was any good. And not just whether it was the best of a set of candidates models, but whether it is a reasonable model in an absolute sense; this is referred to as goodness--of--fit or, model adequacy. While the importance of assessing the adequacy of our models is largely self--evident --- even the best of a set of bad models is still a bad model --- it has received relatively little consideration in phylogenetic comparative biology. Modern phylogenetic comparative methods (PCMs) are almost exclusively model--based \citep[recently reviewed in][]{Omeara2012, PennellHarmon}. Whether we want to ask whether two traits are evolutionary correlated \citep[e.g.][]{Felsenstein1985, Grafen1989, HarveyPagel1991}, what the general pattern of trait evolution has been through a group's history \citep[e.g.][]{Mooers1999, Harmon2010, Hunt2012} or what features an ancestor may have had \citep[e.g.][]{Schluter1997, Huelsenbeck2003}, we need a statistical model which describes the pattern of trait evolution across the phylogeny. While many models for trait change and (increasingly sophisticated) methods for fitting them have been developed, we generally have very little idea as to whether the model we are using for a particular inference is adequate. What is worse is that it is often not even any thought when PCMs are applied. To borrow Rumsfeld's taxonomy, it has largely been an ``unknown unknown''.

Modeling trait evolution along a phylogeny is certainly a challenging task; the trajectory of phenotypic evolution is likely to be very complex --- for example, body--size evolution across a group has almost certainly been subject to a myriad of selective (and non--selective) pressures throughout their histories. Nonetheless, it may be the case that the pattern of phenotypic evolution can be captured by relatively simplistic models; even if most of the details are missing, such models may be useful for quantiatively addressing macroevolutionary hypotheses. Throughout this paper, the focus is on models of quantitative traits --- those such as the height of a tree or the mass of a seed. Brownian motion is the simplest, oldest, and most used, of such models in phylogenetic biology  \citep[BM;][]{Edwards1964, Felsenstein1973, Thompson1975}. In a BM model, the variance of a trait is assumed to accumulate linearly through time at some constant rate (usually denoted $\sigma^2$). Such a pattern may result from either genetic drift \citep{Lande1976, HansenMartins1996}, randomly varying selection \citep{Felsenstein1973, Felsenstein1988} or else simply reflect the summation of many processes operating over macroevolutionary time \citep{HansenMartins1996, Uyeda2011, PennellHarmon, PennellPE}. Whatever, the mechanism, BM has proven to be an extremely useful model in comparative biology; it is the probabilistic model underlying Felsenstein's Independent Contrasts method \citep[][see below]{Felsenstein1985} and is generally considered the null model against which all other models are compared \citep{Blomberg2003}. %WKC: Original math for BM was Einstein (1956, Investigations of the Theory of Brownian Movement ).  Interestingly it's only an analog, even for  molecules moving in a liquid; it's just represents a very simple continuous-time stochastic process.  It just turns out to have a lot of nice features mathematically and to be an adequate model for molecules moving in a liquid, not first-principle physics. 
 
Another model of quantitative trait evolution is the Ornstein--Uhlenbeck process \citep[OU;][]{Felsenstein1988, Hansen1997}, which can (very) loosely be described as ``evolution on a spring''. Under an OU model, variance accumulates at a rate $\sigma^2$, but is ``pulled'' towards a mean value $\theta$ with some strength $\alpha$. This is mathematically equivalent to the case of stabilizing selection on a quantitative trait within a population \citep{Lande1976}, though interpreting it as such is almost certainly incorrect \citep{HansenMartins1996, PennellHarmon}.  
Alternate models that have been considered include: the ``Early Burst'' \citep[EB;][]{Blomberg2003, Harmon2010, SlaterPennell} model, in which most of the evolution occurs early in the clades history; a BM model with a trend in the mean trait value \citep{Hunt2006}; models depicting jumps in phenotypic space \citep{Landis2012, Eastmanlevy}; and other variations on the models described above \citep[e.g.][]{Pagel1997, Pagel1999, ButlerKing2004, Omeara2006, Eastman2011, Beaulieu2012, SlaterMEE}. 

Comparative biologists may use these models in a number of different ways \citep{Freckleton2011, PennellHarmon}; the fit of the model may be used directly to make inferences regarding the ``tempo and mode'' of trait evolution \citep{HansenMartins1996, Mooers1999, Harmon2010} or else may be used to make secondary inferences, such as estimating the evolutionary correlation between traits \citep{Felsenstein1985}. In either case, it is important to consider the adequacy of the model that is used. For example, in the former application, if the ``true'' model of trait change resembles a multi--rate BM process \citep{Omeara2006, Thomas2006, Eastman2011} but we only consider BM and OU as alternative models, we might infer that an OU model is the best--fit, but would be completely misled regarding what processes were important in the evolution of the group. In the latter application, using an inadequate model would artificially decrease the confidence intervals around the estimate of the relationship between the traits in much the same way that neglecting the phylogeny altogether would \citep{Rohlf2006}. The question of model adequacy is even more pertinent as the scale of comparative data continues to grow. Comparative analyses are increasingly being performed on very large datasets including thousands and even tens of thousands of species \citep[e.g.][]{Coopermammal, Jetz2012, Rabosky2013, Cornwell2013, PyronBurbrink2013, Zanne2013}. While a simple model of trait evolution may suffice for a small clade of closely related organisms (e.g. seed size across Oak species), it seems unlikely that this would be true at much broader scales (e.g. seed size across all Angiosperms). 

There has been substantial investigation and discussion of model adequacy in the context of phylogenetic inference \citep[e.g.][]{GautLewis1995, SullivanSwofford, Goldman, HuelsenbeckBull1996, SandersonKim, Bollback2002, Ripplinger2010, Lewis2013, Brown2013} and it forms the basis for the Decision--Theoretic approach to model selection \citep{Minin2003, SullivanJoyce2005}. Contrastly, in phylogenetic comparative biology, researchers are just starting to begin to think about ways to assess model adequacy, especially for models more complex that a simple BM process. We note however, that despite the paucity of approaches, there has historically been a lot of discussion surrounding the appropriateness of various models for PCMs, particularly in the pioneering days of the field \citep[e.g.][]{Felsenstein1985, Felsenstein1988, HarveyPagel1991, Garland1992, Pagel1993, Diaz1996, Price1997, GarlandIves2000, Hansen2012} and our own approach draws heavy inspiration from these earlier works.

Recently, two papers have developed simulation--based approaches to assessing the fit of models \citep{Boettiger2012, SlaterPennell}. While their details differ, the aim of both of these, is to assess whether the data was informative enough to select amongst two candidate models. However, a broader question is whether a given model is a good fit to the data on its own terms --- that is, compared to the universe of possible models we might consider. Here we develop a approach to statistically evaluate absolute goodness--of--fit for models of continuous character evolution. The basic idea of our approach is rather simple. If we have a trait that has evolved on the phylogeny via a BM process with a rate ($\sigma^2$) equal to 1, the contrasts \citep[\textit{sensu}][see below]{Felsenstein1985} will be independent and identically distributed (I.I.D.) according to a standard normal distribution $\mathcal{N}(0,1)$. In our approach, we first rescale the phylogeny according to the model fit, such that if the model were the generating model, the trait data would be distributed as it would be under a BM process with a rate of 1 (which we will refer to as a ``unit tree''). We then calculate the contrasts at each node and compute a set of summary statistics, which capture different aspects of the variance. We then simulate datasets under BM (again, using $\sigma^2 = 1$) and calculate our summary statistics on each simulated dataset. We can then compare our observed to our simulated summary statistics (details below), allowing us to evaluate whether our model we have chosen is indeed an adequate one. 

%% Luke suggested I just cut these. Too much extraneous information

%\citet{Boettiger2012} developed a ``phylogenetic monte carlo'' approach to assess when a given comparative data set contained enough information to distinguish between two candidate models. In brief, their procedure was as follows: 1) select 2 candidate models $\mathcal{M}_0$ and $\mathcal{M}_1$; 2) fit $\mathcal{M}_0$ and $\mathcal{M}_1$ to the data using Maximum likelihood; 3) use the MLE for model parameters $\hat{\Theta}$ to simulate $n$ data sets; 4) for each of the $n$ data sets simulated under $\mathcal{M}_0$, fit both $\mathcal{M}_0$ and $\mathcal{M}_1$ and calculate difference in likelihood values $\delta = -2(L_{\mathcal{M}_0} - L_{\mathcal{M}_1})$; and 5) compare distribution of $\delta$ for datasets simulated under $\mathcal{M}_0$ with distribution of $\delta$ for datasets simulated under $\mathcal{M}_1$. \citet{Boettiger2012} demonstrated that their approach had much better ``classical'' statistical properties (specifically Type--I and Type--II errors) compared to using Information Theoretic methods of model selection, such as AIC \citep{Akaike1974}, AICc \citep{AICC}, and BIC \citep{Schwarz1978}. (Though we note that this is not an entirely fair comparison; Information Theoretic approaches differ philosophically from frequentist approaches to model selection  and do not have Type--I and Type--II error rates in the same way likelihood ratio tests \citep{Wilkes1938} are expected to have.)

%In the other paper, \citet{SlaterPennell} also focused on the case of comparing two models. Their method differs from that of \citet{Boettiger2012} in that theirs was a fully Bayesian posterior predictive approach specifically aimed at detecting ``early bursts'' of trait evolution \citep[\textit{sensu}][]{Simpson1944, Harmon2010}. They estimated the posterior distribution of parameters for a candidate model (here either BM or EB), then sampled parameter values from the joint posterior distribution. They then simulated data under the sampled parameters and then used two alternative summary statistics --- the relationship between the logarithm of the phylogenetic independent contrasts and the height above the root that the contrasts was inferred \citep[a.k.a. the ``node height test'';][]{FreckletonHarvey2006}, and the Mean Disparity Index \citep[MDI;][]{Harmon2003, Slater2010} --- to evaluate whether the observed summary statistics were consistent with the summary statistics computed on the simulated datasets and thus decide whether the model was adequate. They showed that conducting this procedure on both BM and EB models was more powerful and reliable in distinguishing an early burst of trait evolution compared to more conventional approaches (such as model comparison using AIC).


We use our approach to evaluate the ability of simple models to describe the evolution of functional traits in Angiosperms (flowering plants) at a number of different scales. We gathered data on three traits from the literature --- specific leaf area (SLA), seed mass and nitrogen content, all of which are commonly used proxies for functional variation, such as hydrodynamic cycling, life history, and photsynthetic capabilities, respectively \citep{Westoby2002} --- and matched these data to a recently published phylogeny \citep{Zanne2013}. We fit three simple models of trait evolution \citep[BM, OU, and EB, after][]{Harmon2010} to a large number of subclades, pulling out families, orders and unnamed clades taken from time--slices across the tree. We then used our model adequacy approach to ask whether the best--fit model was actually a good fit in an absolute sense. We also re--examined the evidence for a correlation between SLA and leaf Nitrogen content using our framework, a well--supported pattern in non--phylogenetic studies \citep[e.g.][]{Wright2004}.

%% PARAGRAPH: THESE ARE THE QUESTIONS WE WANT TO ADDRESS WITH THIS DATA.
%% not sure exactly what to do here.
%As researchers interested in macroevolution, we would like to understand how such trait diversity came to be --- the who, what, when, where and whys of deep time. For example, seed size is associated with many other life--history triats [give example] and varies $\sim$ 11 orders of magnitude across extant angiosperm species \citep{Westoby1992TREE, Moles2005}. [Talk about other things we know about seed size; cite Lord 1995, Westoby 2002, Moles 2005, Cornwell 2013, etc.]


\section*{A framework for assessing model adequacy}

Our approach is based on the use of Felsenstein's \citep{Felsenstein1973, Felsenstein1985} Phylogenetic Independent Contrasts (PIC) method, which we will briefly review \citep[for more details, see][]{Felsenstein1985, Rohlf2001, Blomberg2012}. We have observed trait values $X_1, X_2, \ldots, X_n$ at the tips of a phylogenetic tree $\mathcal{T}$ consisting of $n$ species. Due to shared history of ancestry between the tips, $X_1, X_2, \ldots, X_n$ are not independent observations. To deal with this problem, Felsenstein suggested computing the $n-1$ contrasts $c_1, c_2, \ldots, c_{n-1}$, the differences $X_{i} - X_{j}$ between the observations at tips $i$ and $j$. If we assume a BM model of trait evolution, in which variation accumulates directly proportional to time, these contrasts will be independent and identically distributed (I.I.D.) --- hence the name, ``PICs''. The procedure can be described algorithmically: 1) Take the contrast $c = X_i - X_j$ at node $k$, where $k$ is the most recent common ancestor of tips $i$ and $j$. 2) Standardize the contrast by its dividing by its standard deviation, which under BM is $\sqrt{v_i + v_j}$, the square root of the sum of the branch lengths $v$ leading to $i$ and $j$, 3) Estimate a trait value for the ancestral node $k$ by taking the mean of its descendants' trait values, weighted by their branch lengths

\begin{equation}
X_k = \frac{(1 / v_i)X_i + (1 / v_j)X_j}{1/v_i + 1/v_j}.
\end{equation}

4) Lengthen the branch below $k$ by $v_i v_j / (v_i + v_j)$, in order to account for error in the estimation of $k$. Iterating across all nodes in the phylogeny, the result is a set of contrasts $\mathbf{c}$, which, as stated above, will be I.I.D. only if the model which generated the observations was BM \citep{Felsenstein1985, Rohlf2001}. As our method described in this paper essentially evaluates whether this condition holds, we will refer to $\mathbf{c}$ as contrasts, rather than ``PICs'' throughout.

The basic principle of our approach is straightforward. Given a set of $n$ observations, we can compute the $n-1$ contrasts. We calculate a set of summary statistics on the ``observed'' contrasts $\mathcal{S}^*$. We then simulate $N$ datasets using a Brownian motion model of trait evolution, compute the contrasts on each data set and calculate the same summary statistics $\mathcal{S}$. We then compare $\mathcal{S}^*$ to $\mathcal{S}$. If $\mathcal{S}^*$ lies in the tails of $\mathcal{S}$, our model is not capturing variation along a relevant axis.
%% This is sort of a rehashing of what is already in the introduction. 
%% I think it is useful in both places.

\subsection*{Summary statistics}

To assess model adequacy we have chosen 6 summary statistics $\mathcal{S} = \lbrace \mathcal{S}_1, \ldots, \mathcal{S}_6 \rbrace$

\begin{enumerate}
\item[$\mathcal{S}_1$] The mean of the squared contrasts. This is equivalent to the Restricted maximum likelihood (REML) estimate of the Brownian motion rate parameter $\sigma^2$ \citep{Garland1992, Rohlf2001}. We chose this statistic to detect misestimation of the BM rate parameter.

\item[$\mathcal{S}_2$] The variance in the absolute value of the contrasts. We used this statistic to detect heterogeneity in the rate of trait evolution \citep[\textit{sensu}][]{Omeara2006, Eastman2011}.

\item[$\mathcal{S}_3$] The slope resulting from fitting a linear model between the absolute value of the contrasts and their expected variances. Again, each (standardized) contrast has an expected variance proportional to $v_i + v_j$  \citep{Felsenstein1985}. Under a model of BM, we expect no relationship between these. In using this, we are asking whether the contrasts are larger or smaller than we expect based on their branch lengths. If, for example, more evolution occured per unit time on short branches than long branches, we would observe a negative slope.

\item[$\mathcal{S}_4$] The slope resulting from fitting a linear model between the absolute value of the contrasts and the inferred ancestral state. We estimated the ancestral state using the least--squared method suggested by \citep{Felsenstein1985} for the calculation of contrasts. We note that this is not technically an ancestral state reconstruction and differs from more commonly applied approaches \citep[such as the  maximum likelihood estimator][]{Schluter1997} in that it reconstructs the ancestral states node by node, such that the reconstructions are marginal rather than joint reconstructions, and that does not consider the error in any given estimate. While we do not suggest that this is a reliable method for ancestral state reconstruction, for our purposes it is advantagous in that it is internally consistent with the calculation of the states, such that we have a clear expectation that the test statistic will be 0 if the model is correct; it is also computationally efficient, allowing us to quickly apply it to many simulations. We used this statistic to evaluate whether there is variation in rates relative to the trait value (e.g. do larger organisms evolve faster?)

\item[$\mathcal{S}_5$] The slope resulting from fitting a linear model between the absolute value of the contrasts and the height above the root at which they are inferred. This is used to capture variation relative to time and is alternatively known as the ``node--height test'' \citep{FreckletonHarvey2006, SlaterPennell} for detecting early bursts of trait evolution. It has been  previously used to assess the fit of BM models.

\item[$\mathcal{S}_6$] The D--statistic obtained from Kolmolgorov-Smirnov test from comparing the distribution of contrasts to that of a normal distribution with mean 0 and standard deviation $\sqrt{\overline{\mathbf{c}^2}}$ --- the expected distribution of the contrasts under BM \citep{Felsenstein1985, Rohlf2001}. We chose this to capture deviations from normality, such as would be produced if traits evolved via a ``jump diffusion'' type model \citep{Landis2012, Eastmanlevy}, in which trait evolution may occasionally occur at rates much greater than the background rates \citep[see][]{PennellPE}. We used the empirically estimated standard deviation, rather than the expected (i.e. assuming $\sigma^2=1$) to make $\mathcal{S}_1$ and $\mathcal{S}_6$ more independent.

\end{enumerate}

The three summary statistics fitting a linear model between the contrasts and some aspect of the data (i.e. $\mathcal{S}_3, \mathcal{S}_4, \mathcal{S}_5$) were developed by Garland and colleagues \citep{Garland1992, Garland1993,  Diaz1996} to test for adequacy of BM prior to performing PICs \citep{Felsenstein1985} or phylogenetic regression \citep{Grafen1989}. They were implemented in the program \texttt{PDAP} \citep{Garland1993, Midford2005} and have been well used in the comparative methods literature (at least until more recently).

We have chosen these statistics because they capture a range of dimensions of variability wherein the model may not be adequate. However, they are certainly not exhaustive. One could, for instance, calculate the median of the squared contrasts, the skew of the distribution of contrasts, etc. If the generating (i.e. ``true'') model was known, we could use established procedures for selecting a set of sufficient (or approximately sufficient) summary statistics \citep[e.g.][]{MajoramJoyce, Slater2012MECCA}. However, the aim of our project is to seek a set of summary statistics that capture violations of the assumption that the contrasts are I.I.D. and thus we do not have the generating model in hand. Our chosen statistics appear to capture a wide variety of model misspecifications but this does not mean that they will necessarily capture any type of model misspecification. Researchers interested in specific questions are encouraged to try alternate sets of summary statistics; we have made the software implementation of our approach as flexible as possible to accomodate alternative sets of statistics. (We describe how users of our software can easily implement these in the Online Supplementary Materials.) We also note that a model will be considered inadequate if it is rejected by any of the summary statistics that can be used. In principle, one could evaluate the model fit with a large number $N$ of summary statistics and the model rejected even if it is only the $N^{th}$ summary statistic fails. We note that this is not a situation where we need to account for multiple comparisons. In evaluating $n$ summary statistics, we are not performing $n$ independent tests but looking at exact same results from multiple angles. Furthermore, even if the model is not rejected by any of the summary statistics used, we still do not know if there adding another statistic would cause us to reject the model. This is perhaps a somewhat unsatisfying situation to be in but we have to learn to live with it. The choice of how many summary statistics to use is ultimately one of balancing statistical intuition and computational effort and there is no good statistical theory to guide us as to which summary statistics to use and how many are enough \citep{Gelmanbook}.

\subsection*{Rescaling the phylogeny to construct a ``unit tree''}

Readers may have realized that while the above summary statistics are appropriate for a BM model of trait evolution, the same will not be true of alternative models. That is because under alternative models, we no longer expect the contrasts to have I.I.D. properties (indeed, this is the rationale for using such statistics as the ``node height test'' \citep{FreckletonHarvey2006} to look for early bursts of trait evolution). Our solution to the problem is to use the estimated parameters of a more complex model $\Theta$ to create what we term a ``unit tree''. A unit tree is defined as a tree in which if the model we fit is the true model, the data at the tips will be distributed as it would be under a BM process with a rate $\sigma^2$ equal to 1. Any phylogenetic tree $\mathcal{T}$ can be completely described by a $n \times n$ variance--covariance (vcv) matrix $\mathbf{C}$, where $n$ is equal to the number of tips in $\mathcal{T}$. The elements $C_{i,j}$ are the shared path--length from the root to the most recent common ancestor of $i$ and $j$ \citep{Piazza1975}. The diagonal elements ($i = j$) are simply the total distance from the root to the tips. For any model, we can describe a second matrix $\mathbf{\Sigma}$, which is the expected vcv matrix between observations at the tips. For example, under BM, in which variation accumulates proportionally to time under a single rate $\sigma^2$,
\begin{equation}
\Sigma_{ij} = \sigma^2 C_{ij}
\end{equation}
and thus
\begin{equation}
\mathbf{\Sigma} = \sigma^2 \mathbf{C}.
\end{equation}
We can similarily construct $\mathbf{\Sigma}$ based on whatever model we are interested in. \citet{HoAne2013} describe a condition which they refer to as the ``3 point condition''; a vcv matrix $\mathbf{\Sigma}$ satisfies this condition if, and only if, it is symmetric, has only non--negative entries and that for any $i,j,k$, the two smallest of $\Sigma_{i,j}, \Sigma_{j,k}, \Sigma_{i,k}$ are equal. They prove that a) this condition is only met for rooted phylogenies with trait data generated under BM; and b) that any $\mathbf{\Sigma}$ based on a multivariate Gaussian distribution can be rescaled to satisfy the condition. Our concept of a unit tree is equivalent to their ``3 point condition'' which the additional requirement that rate parameter of the BM model is equal to 1. This last requirement puts all models on the same scale so that it is more intutive to compare them; however, this is not strictly necessary for our approach. As stated above, a unit tree can be constructed from any multivariate Gaussian model such as mulit--rate BM \citep{Omeara2006, Thomas2006, Eastman2011, Revell2012, Motmot}, Pagel's $\lambda$, $\kappa$, and $\delta$ transformations \citep{Pagel1997, Pagel1999}, the AC/DC model \citep{Blomberg2003} \citep[a.k.a. `EB';][]{Harmon2010, SlaterPennell}, models with a directional trend \citep{Hunt2007} and others \citep[e.g.][]{SlaterMEE}. OU models can also be rescaled to form a unit tree; this is true of both multi--optimum \citep{ButlerKing2004} models and the more generalized form \citep{Beaulieu2012, IngramMahler, UyedaBayou} in which the optimum, $\sigma^2$ and $\alpha$ values all vary across the tree \citep{HoAne2013}. We note that all of above applies to both ultrametric and non--ultrametric phylogenies \citep{HoAne2013}, such that the methods we describe can be applied to trees consisting of fossil taxa as well.

The approach we describe is applicable to univariate and additionally to multivariate analyses, such as ``phylogenetic regression'' (e.g. ``phylogenetic generalized least squares''; PGLS) analyses, in which the aim is to test for evolutionary correlations between traits \citep{Grafen1989, Rohlf2001}. In general terms, we can write down the regression equation as:

\begin{equation}
\mathbf{y} = \mathbf{b}\mathbf{X} + \epsilon .
\end{equation}

Here $\mathbf{y}$ is the $n \times 1$ vector of the dependent variable, $\mathbf{b}$ is the vector of partial regression coefficients, $\mathbf{X}$ is the $n \times q$ matrix of independent variables ($q$ being the number of traits included in the model) and $\epsilon$ is the error term. In ordinary least squared (OLS) regression, we assume that the error term $\epsilon$ is normally distributed with parameters $(0, \sigma^2)$. However, when we taken into account the covariation between tip observation due to the pattern of shared ancestry, the residuals are no longer I.I.D. and will be distributed $\mathcal{N} (0, \mathbf{\Sigma})$, where again $\mathbf{\Sigma}$ is the estimated vcv matrix from fitting the evolutinary model. While the original version of PGLS assumed a BM model of trait evolution, this has been expanded to include a number of models, including the $\lambda$ model \citep{Pagel1997, Revell2010, Freckleton2011} and OU \citep[e.g.][]{Hansen2008} among others \citep[see also][]{Lynch1991, Hadfield2010}. Similar to the univariate case described above, these regression equations fundamentally depend on the use of an appropriate model \citep{Hansen2012}. To assess the adequacy of the model used to estimate $\mathbf{\Sigma}$, we can use an identical approach to the one described above, but rather that take the contrasts of the trait values, we take the contrasts of the residuals from fitting our regression model to the data. This may not appear intuitive, but phylogenetic regression models do not apply the covariance matrix to the data themselves, only to the residuals; in other words, the phylogenetic structure of actual data does not matter, only that of the residuals \citep{Rohlf2001, Revell2010}. Therefore, if the model specifiying $\mathbf{\Sigma}$ is correct, the contrasts of the residuals taken along the unit tree will also be I.I.D. If the correlation structure is BM, then we can obtain the REML estimate of $\sigma^2$ directly from the contrasts of residuals (see summary statistic $\mathcal{S}_1$). If some other correlation structure is used \citep[such as a $\lambda$ transformation][]{Pagel1997}, we must first rescale $\mathbf{C}$ according to the estimated parameter, then use the transformed tree to estimate $\sigma^2$. We note that while the approach presented here can be used to evaluate the adequacy of the trait model, it does not assess the adequacy of the linear component of the model $\mathbf{y} = \mathbf{b}\mathbf{X}$. It is also worth noting that even if $\mathbf{\Sigma}$ is misspecified or misestimated, such as by using an incorrect model or an incorrect tree, the GLS estimate of the slope $\mathbf{b}$ will be unbiased \citep{Rao1999}; however the variance of the estimator will be too small \citep{Rohlf2006}. And where deviations from the true $\mathbf{b}$ do occur, the directions of the deviations (i.e. a higher or lower regression coefficient) are not necessarily predictable \citep{Rohlf2006}.

%% Using REML Estimate instead of gls here
%% For the record, the gls estimator is 
%\begin{equation}
%\hat{\sigma^2} = \frac{(y - \hat{\alpha}\mathbf{X})^T \mathbf{C^{-1}} (y - \hat{\alpha}\mathbf{X})}{N-1} 
%\end{equation}
%\citep{GarlandIves2000, Freckleton2002}, where again $\mathbf{C}$ is the vcv matrix describing the phylogeny,
% $\hat{\alpha}$ is the estimated rooted state and $\mathbf{X}$ is a $n \times 1$ identity matrix.

\section*{Model adequacy and the evolution of Angiosperm functional traits}
As an exploration of the importance of model adequacy in real data, we collected large comparative datasets from the literature --- specifically of key functional traits across Angiosperms --- and applied our approach for assessing model adequacy. We used a phylogeny of Angiosperms from a recent study by \citet{Zanne2013}. The tree contains 31,749 land plant taxa and covers xx \% of familial diversity and yy \% of generic diversity across all Angiosperms. We will not provide the details on the phylogeny here and refer interested readers to the original publication \citep{Zanne2013}. For the purposes of this study, we used the MLE point estimate of the phylogeny. We could have used a set of bootstrapped trees and ran our analyses across all of them, but for our purposes, it should not qualitatively affect our results. This tree is published in \textsc{dryad} (accession number).

We used large datasets on three important, continuous plant traits: specific leaf area, leaf nitrogen content, and seed mass.  All data are available via the internet (see Supplemental Material for specific locations and scripts to access and process the original data; due to licensing considerations, they could not be published in a complete form with this manuscript). Specific leaf area (SLA) and leaf nitrogen data comes from \citet{Wright2004} with additional SLA data from the LEDA project \citep{Kleyer2008}.   Seed mass data comes Kew \citep{Kew2008}.  Geometric species means were used for all three traits.  The full data set includes 3369 species for SLA of which XX correspond to species in the \citet{Zanne2013} tree.  The sample size for leaf N is XX and YY; for seed mass it is ZZ and FF.  

%% NEED TO ADD MORE DETAILS ON HOW SE WAS OBTAINED
To (partially) account for measurement error, we estimated the standard error (SE) for each of the three traits doing [something here]. For practical purposes, we assumed that the SE was constant across the phylogeny as we only had within--species sampling for a subset of the taxa. This assumption is likely unwarranted but even a somewhat inaccurate estimate of measurement error is better than not assuming any measurement error at all \citep{HarmonLosos2005}.

We first matched our trait data to the Angiosperm phylogeny from \citet{Zanne2013} and then extraced subclades from this dataset in a few ways: using families, using orders and time slicing the tree at 50my intervals and extracting any (named or unnamed) clades for which the most recent common ancestor of a group was younger than the timeslice. (In the ML tree, the crown age of Angiosperms is estimated to be 400.7877 my.) We kept only subclades for which there was at least 20 species which occured in both the phylogeny and trait data so that we had a reasonable ability to estimate model parameters and distinguish between models. For SLA, this left us with AA clades, seed mass BB clades and leaf nitrogen content CC clades. We will note that these are of course non--independent, many of the same taxa were included in family, order and time--slice subtrees. 

We focused the analysis on a few simple models of trait evolution for the univariate case --- BM, OU and EB. We did this, not because we think that these models are likely to perform well at all scales but rather because it was intuitive to explore the statistical properties of model adequacy across scale and because they are the same models used in a recent large--scale analysis of evolutionary mode \citep{Harmon2010} which served as a natural comparison. Similarly for the multivariate analyses, we only considered two commonly used models for the correlation structure, BM and Pagel's $\lambda$ transform \citep{Pagel1997} \citep[see, for example][]{Revell2010, Freckleton2011}. As the purpose of the empirical analyses was to examine the consequences of considering model adequacy rather than to comprehensively characterize the evolutionary patterns of these traits, we thought that simple models were more appropriate for this.

For each subtree and each trait, we performed two sets of analyses: one Bayesian, the other using maximum likelihood. For the Bayesian analysis, we fit the three models (BM, OU and EB) using a MCMC approach, sampling paramter values using the slice sampling method \citep{Nealslice}, as implemented in the \texttt{R} package \texttt{diversitree} \citep{FitzJohn2012}. For the BM model we set a uniform prior on $\sigma^2 \sim \mathcal{U}[0, 2 \mathrm{Var}[x]]$ where $x$ is the tip states. For the OU model, we used the same prior for $\sigma^2$ and a uniform prior on $\alpha \sim \mathcal{U}[0, 2 \sigma^2 / t_{min}]$ where $t_{min}$ is the length of the shortest tip branch. For the EB model, we again used the same prior for $\sigma^2$ and a uniform prior on $a$, the rate of decrease in $\sigma^2$, such that $a \sim \mathcal{U}[\log (10^{-5})/T_{max}, 0]$ where $T_{max}$ is the depth of the tree \citep[for rationale, see][]{SlaterPennell}. We ran each Markov chain for 100,000 steps, which preliminary investigated demonstrated was more than sufficient to obtain convergence and proper mixing. We compared the models using the Deviance Information Criterion \citep[DIC;][]{dic} and selected the best--fitting model for further analyses; if there was a tie, we simply selected one of the best--fit at random. Note that while model selection is of course an important and difficult problem in general, we argue that in actuality it does not matter a great deal here. If two models have similar support, the transformed tree based on the respective parameters of the models, will be very much the same and the adequacy results will not differ substantially. For the best--fitting model, we drew 1000 samples from the joint posterior distribution (after removing 10,000 iterations as burn--in). For each of the sampled parameter sets, we used the values to construct a unit tree and calculated our six summary statistics. We then simulated a dataset on the same unit tree and calculated the summary statistics on the simulated data. 
For the ML analysis, we repeated the same general procedure but fit the models using ML with the \texttt{geiger} \citep{geiger} package. We compared the fit of the models using AIC \citep{Akaike1974} and again ran the adequacy analysis on the best--fit model. In this case because we only created the unit tree once based on the ML parameter estimates, we simulated 1000 datasets on this unit tree. For both types of analyses, we computed a p-value by comparing our observed summary statistics (distribution of point estimate) to the distribution of simulated summary statistics. As a multivariate measure of model adequacy, we calculated the mean Mahalanobis distance \citep{mahalanobis1936}, which calculates a scale--invariant distance between the observed summary statistics and the mean of our simulated summary statistics, taking into account the covariance structure between the summary statistics.

We also conducted an analysis of the relationship between leaf nitrogen content and specific leaf area, which has been previously examined in a non--phylogenetic context....

\section*{Results}

\section*{Discussion}

The approach we propose in this paper is designed to be general. It can allow researchers to assess the adequacy of phylogenetic trait models along an arbitrary number of axes of variation and is applicable to arbitrarily complex models of continuous character evolution, so long as the expected distribution of tip states is assumed to be multivariate normal. There are two alternative ways to conceptualize our approach. From a Bayesian perspective, our approach can be considered as a form of posterior predictive check \citep{Rubin1984, Gelman1996, Gelmanbook}. In this case, we fit a model using Bayesian machinery (e.g. Markov chain Monte Carlo, MCMC, methods), then sample parameter values $\Theta$ from the joint posterior distribution. We then obtain a distribution of summary statistics from both the observed and the simulated data; we can then compare these distributions (here we compare only the difference in means, but the variance and skew could also be considered). Alternatively, one can think of our method from a frequentist perspective --- as such, our method can be construed as a form of parametric bootstrapping \citep{Efronbootstrap}. Rather than a distribution of summary statistics, we will get a point estimate of the summary statisitic based on the unit tree constructed from the ML parameter estimates $\hat{\Theta}$ and a set of summary statistics from the simulated data, each one having been simulated on the same unit tree. While the interpretation of the results are necessarily different, in practice, our approach works very much the same way in either case.

\section{Model adequacy for angiosperm functional traits}
Major patterns we found.

\section*{A case study in model adequacy --- seed size evolution in the Meliaceae \& the Fagaceae}
To better illustrate our approach, we have selected two empirical datasets, both of which are subsets of our larger analyses of functional trait evolution in Angiosperms. We collected data on seed mass from the Kew online database \citep{Kew2008} and matched the trait data to the Meliaceae (the ``mahogany'' family) and Fagaceae (the ``beech'' family) subtrees pruned from a larger phylogeny \citep{Zanne2013}. After matching the available data, we had a comparative datasets consisting of 44 species for the Meliaceae and 70 species for the Fagaceae --- both fairly typically sized datasets.  Using the \texttt{R} package \texttt{geiger} \citep{geiger}, we used maximum likelihood to fit both a simple BM model and a simple OU model to the data. In both cases, an OU model was strongly supported; the AIC weight for the OU model was $\sim 0.99$ for both clades. One might be tempted to conclude from this that similar evolutionary processes were occuring in both groups. 

However, from the perspective of model adequacy, the story is very different (see \ref{family-example-fig}). For both clades and both models, we rescaled the phylogeny based on ML parameter estimates, calculated our six summary statistics on the rescaled phylogeny, then simulated 1000 datasets and calculated the summary statistics on each simulated dataset. For the Meliaceae, the OU model was indeed an adequate model; the observed summary statistics were in the middle of the distribution of simulated summary statistics ($\mathcal{S}_1: p=0.448$, $\mathcal{S}_2: p=0.803$, $\mathcal{S}_3: p=0.633$, $\mathcal{S}_4:p=0.496$, $\mathcal{S}_5: p=0.148$, $\mathcal{S}_6: p=0.629$). However, even though OU was highly supported, a BM model also adequately captured the variation in the data ($\mathcal{S}_1: p=0.272$, $\mathcal{S}_2: p=0.987$, $\mathcal{S}_3: p=0.380$, $\mathcal{S}_4:p=0.172$, $\mathcal{S}_5: p=0.360$, $\mathcal{S}_6: p=0.340$), suggesting that model selection via AIC was selecting an overparameterized model; this conclusion is consistent with the findings of \citet{Boettiger2012}. We found the exact opposite for the models fit to the Fagaceae data --- neither OU nor BM were an adequate model for this group. The OU model was shown to be inadequate by both $\mathcal{S}_1$ ($p \sim 0$) and by $\mathcal{S}_2$ ($p=0.006)$; the rest of the observed summary statistics did not differ significantly from the simulated summary statistics ($\mathcal{S}_3: p=0.228$, $\mathcal{S}_4:p=0.364$, $\mathcal{S}_5: p=0.828$, $\mathcal{S}_6: p=0.955$). The BM model performed worse for all these statistics. These results suggest that the reason that the OU model is an inadequate model for the evolution of seed mass in the Fagaceae is that it is not accomodating variation in evolutionary rates across the tree --- both the overall rate $\mathcal{S}_1$ and variance in rate $\mathcal{S}_2$ were not well captured by this model. The reason the OU model was preferred over BM may having nothing at all to do with a ``clade optimum'' or ``stabilizing selection'' but rather the additional parameter may be just explaning some additional noise in the data. The next logical step if we were to pursue this would be to consider multi--rate or mulit--optimum models \citep[e.g.][]{Omeara2006, Eastman2011, Beaulieu2012, UyedaBayou}; however this is beyond the scope of this illustration.


%\subsection*{Why models may be inadequate}
There are a number of (likely interacting) causes for model inadequacy. The most biologically interesting of these is that the evolutionary processes in some group are more complex (or just different) from the processes and patterns accounted for by our model. [talk about real results from the literature; include paleo stuff]. 

Model misspecification is not the only source of error when fitting trait models. Estimating parameters (especially under ML) is often non--trivial owing to identifiability issues in regions of parameter space \citep{Ane2008, HoAne2012} --- these issues are generally underexplored but are likely to be pervasive; even more so for parameter--rich models. As the construction of the unit tree depends on the parameter estimates, our approach will be sensitive to their mis--estimation. Second, measurement error may have pathological effects regarding model adequacy \citep{HarmonLosos2005} and the effects may vary depending on the model used \citep{RevellReynolds2012, PennellPE}. Phylogenetic misestimation may also have an effect on the adequacy of a model. All of the statistical models of trait evolution assume that branch lengths are estimated without error, though in practice this is never actually the case. The influence of branch length error in PCMs is not really known, though what little evidence there is, appears to be mixed \citep{Revell2005, WertheimSanderson2011}. Misestimating topology may have very serious consequences for model adequacy in some types of analysis. For example, if species are paired with the incorrect species, traits may appear to be more dissimilar than they really hard, leading to inflated contrasts and rate estimation close to the tips. Other analyses, such as PGLS and PIC appear to be more robust to error in minor errors in topology \citep{MartinsGarland1991, Losos1994}. A model can be inadequate as a result of any of these and it is often challenging to distinguish the contribution of these in real datasets. Our approach cannot provide a clear reason why a model is inadequate, only indicate that it is.

%\subsection*{An adequate model does not necessarily mean a good model}
The flipside of the above is that simply because a model is estimated to be adequate using our approach does not necessarily mean that the model itself is a good one. First we must consider whether we have enough statistical power to reject a model. The more contrasts we have from a dataset, the more power we have to detect deviances from the expected distribution. We observed a strong positive correlation between a multivariate measure of model (in)adequacy and the number of taxa in a group (see above, figure XX). While as we argue above, it is likely that the pattern of evolution is increasingly complex at larger scales, it is also possible that the simple models we used were on average equally inadequate at all scales and we simply had more power to detect this on larger trees. The power to reject a given model is inversely related to the ability to find support for a model, using some form of model selection; \citet{Boettiger2012} provide some compelling evidence that it is often more difficult to properly distinguish between models than has been conventionally thought.

We also should keep in mind that the both the original model fit and the simulations are both based on the observed tip values. These may or may not be representative of the states that have occured throughout the clade's history. In other words, a model may adequately capture variation in our observed tip values but may be misleading when making inferences. Incorporating fossil taxa has been shown to dramatically alter the estimated model parameters and the evolutionary inferences \citep{FF2006, Slater2012Fossil, SlaterMEE}. Another complication which has the potential to mislead inferences is based sampling of traits \citep{Freckletoninaction, FitzJohnwoody}. All the trait models considered in this study assume that evolution has occured independently on each branch, such that as long as the taxa included in the phylogeny are a more--or--less random sample, the parameter estimates should not be biased as a result \citep{PennellHarmon}. However, in many cases \citep[especially when using large trait databases;][]{FitzJohnwoody} this will not be the case. Importantly this will not be detected by the model adequacy approach presented in this paper: the bias in the parameter estimates will be systematically the same across all the simulated datasets.


\subsection*{Extensions of this approach}
%% Just a clutter of ideas at the moment.
The framework we present here can be extended in number of ways. First, we have only considered a limited set of summary statistics. We chose them because each of these has a clear statistical expectation and observed deviations from them have intuitive explanations. However, they are certainly a subset of all possible summary statistics that could be applied. One thing we did not consider is autocorrelation between neighboring contrasts \citep[see][]{Cheverud1985, Gittleman1990}. One could also potentially use alternative forms of either the contrasts \citep[such as contrasts considering within species variation][]{Felsenstein2008} or alternative ways of assessing the summary statistics \citep[e.g. using robust regression in lieu of fitting standard linear models for the 3 summary statistics involving slope; see][]{SlaterPennell}. Another suggestion would be to regress the value of the contrast versus some measure of nodal support (posterior probabilities or bootstrap support); while the expected distribution is not entirely clear to us, if larger contrasts were associated with nodes of low support, this may suggest that the pattern is driven by the incorrect pairing of species (see above). There are undoubtedly more such summary statistics that creative workers could potentially conceive of and some would be more appropriate than others for different questions.

The method we have described here can apply to any model of trait evolution which can be described by a multivariate normal distribution. That is, where the original tree can be transformed from the model fit to a unit tree. Our approach can therefore not be applied to other types of models, such as those which assume a long--tailed distribution of trait change \citep[e.g.][]{Landis2012} or state--dependent diversification models \citep[e.g.][]{Bokma2008, FitzJohn2010}. And it is not applicable to models of discrete character evolution, such as the Mk model \citep{Pagel1994, Lewis2001} and variations thereof \citep[e.g.][]{Maddison2007, WagnerMarcot2010, Marazzi2012, Beaulieu2013} \citep[but see Felsenstein's threshold model;][]{Felsenstein2005, Felsenstein2012}. Methods to evaluate the adequacy of discrete character models are also sorely needed as the issue is just as pertinent in this case \citep{ReadNee1995}, though the statistics involved will necessarily be different. Likewise, similar approaches could also be adopted for evaluating the adequacy of models of lineage diversification; some work has been done on this \citep[e.g.][]{Rabosky2009AmNat, Rabosky2012} but we do not yet have a general method for looking at this, especially for complex models of diversification \citep[e.g.][]{Stadler2011, Etienne2012}.

Another possibility which our approach suggests is that researchers could potentially use the summary statistics as a means to perform question--specific model selection. This is the essence of the ``node--height'' test for detecting early bursts of trait evolution \citep{FreckletonHarvey2006}. \citet{SlaterPennell} extended the logic of this is a fully Bayesian posterior--predictive method for distinguishing between these models. For some problem, we may be care a lot about whether the model is capturing the variance in some axis (or axes) and be less concerned about others. We could then use posterior predictive simulations and a well--chosen set of summary statistics to help guide us \citep[see][]{Bollback2002}. This is related to the statistical field of decision--theory \citep[for excellent and comprehensive introductions, see][]{Berger1993, Robert2007}, which has proven to be very useful in selecting between models of sequence evolution \citep{Minin2003, SullivanJoyce2005}. Such an approach has not been previously considered in comparative methods but could be extremely useful.

There is much fertile ground to explore regarding how best to think about modeling trait evolution. The recent growth in comparative methods is extremely exciting. However, we would argue that it is still not clear how best to analyze comparative data and model trait evolution, especially when considering evolutionary patterns and process across large scales. One thing that we think will be important is a serious consideration of what our models are doing and when they are appropriate. We hope that our approach can help move model adequacy from being an ``unknown unknown''  to being a ``known known'' or at least a ``known unknown'' --- that is to say, we may not know exactly why our model is not capturing the variation in the data, but at least we will know it is not.


\section*{A note on implementation}

The method described here has been implemented in an R package \texttt{arbutus}. It is available on CRAN and at \texttt{www.github.com/mwpennell/arbutus}. For this project, we have also adopted code from the \texttt{ape} \citep{ape}, \texttt{geiger} \citep{geiger}, \texttt{diversitree} \citep{FitzJohn2012} and \texttt{ggplot2} \citep{ggplot2} libraries. We have written functions to parse the output of a number of different programs for fitting trait evolution models (see \ref{supp-table-fxns}). As this approach was developed to be general, we have written the code in such a way that users can include their own summary statistics and trait models in the analyses; we include demonstrations of how this can be done in the supplementary material.

\section*{Concluding remarks}

While we describe this as a novel approach, much of it stems directly from earlier work in the field. In the 1980s and 1990s --- the time when phylogenetic comparative biology was just starting to emerge as a discipline --- much discussion surrounded the appropriateness of various methods and models [cite lots including some missteps, e.g. Westoby 1995]. However, as phylogenetic approaches have become more widely accepted and applied in a variety of fields, including community ecology \citep{Webb2002, CB2009, Mayfield2010, PennellHarmon}, paleobiology \citep{Hunt2012}, anthropology \citep{Nunnbook}, etc., much of this debate has seemingly been largely forgotten \citep[but see][]{Losos2011, Hansen2012}. However, as the scale of phylogenetic comparative data has grown, these concerns regarding model adequacy are more pertinent than ever. We argue that evaluating the fit of macroevolutionary models ought to be an important component of any comparative analysis. The approach we develop in this paper can generally be applied to a variety of continuous trait models. Alternative approaches that can apply to discrete models (binary, multistate and ordinal) as well as continuous trait models which are not multivariate normal are needed. If nothing else, we hope that our article spurs renewed interest in understanding when models capture the information we are interested in. \citet[][p. 14]{Felsenstein1985} wrote that ``[p]hylogenies are fundamental to comparative biology; there is no doing it without taking them into account''. We agree, but would add that models are also fundamental to comparative biology and that there is no doing it without considering their adequacy.


\section*{Acknowledgments}

We would like to thank the members of the Tempo and Mode of Trait Evolution Working Group at the National Evolutionary Synthesis Center (NESCent) as well as NESCent for funding our group. Josef Uyeda, Paul Joyce, and Daniel Caetano also provided insightful comments on this project. MWP was supported by a Bioinformatics and Computational Biology Graduate Fellowship from the University of Idaho and a NSERC post--graduate fellowship. LJH was supported by NSF (AVAToL ).



\newpage
\bibliographystyle{amnat}
\bibliography{model_ad.bib}

\end{document}
