\documentclass[a4paper,12pt]{article}
\usepackage[osf]{mathpazo}
\usepackage{ms}
\usepackage[numbers, sort&compress]{natbib}
\usepackage{lineno}
\usepackage{graphicx}
\usepackage{caption}
\modulolinenumbers[5]
\linenumbers

\pdfminorversion=3

\makeatletter
\renewcommand{\@biblabel}[1]{\quad#1.}
\makeatother

\title{The adequacy of phylogenetic trait models}
\author{
Matthew W. Pennell$^{1, *}$, Richard G. FitzJohn$^2$,\\
William K. Cornwell$^{3}$ \& Luke J. Harmon$^{1,4}$
}

\date{}
\affiliation{
 $^{1}$ Department of Biological Sciences \& Institute for Bioinformatics and Evolutionary Studies, University of Idaho, Moscow, ID 83844, U.S.A.\\ 
 $^{*}$ Email for correspondence: \texttt{mwpennell@gmail.com}\\
 $^{2}$ Department of Biological Sciences, Macquarie University, Sydney, NSW 2109, Australia;
\texttt{rich.fitzjohn@gmail.com}\\
 $^{3}$ School of Biological, Earth and Environmental Sciences, University of New South Wales, Sydney, NSW 2052, Australia; \texttt{w.cornwell@unsw.edu.au}\\
 $^{4}$ \texttt{lukeh@uidaho.edu}
}

\runninghead{are macroevolutionary models adequate?}
\keywords{comparative methods, model adequacy, independent contrasts, Brownian motion}


\begin{document}

\mstitlepage
\parindent=1.5em
\addtolength{\parskip}{.3em}
\vfill

\singlespacing
\section{Abstract}
Investigating evolutionary hypotheses using interspecific data requires both a
phylogeny and a statistical model that describes the evolution of the trait through time.
A wide variety of such models have been proposed, all of which necessarily make
simplifying assumptions. An often over--looked statistical question is whether the model
used is actually capturing relevant variation in traits. A model may be the best fit
relative to a set of candidate models, using some model selection criterion, but it may
still be a poor fit in an absolute sense; however, we lack methods to evaluate this. Here
we develop a general framework for assessing the fit (or, adequacy) of quantitative trait
models, based on Felsenstein's Independent Contrasts method. Our framework can be
applied to arbitrarily complex trait models as long as the tip values can be assumed to
follow a multivariate normal distribution; this is the case for most commonly used trait
models such as Brownian motion and the Ornstein--Uhlenbeck process and applies
equally well to phylogenetic regression models (e.g. phylogenetic generalized least
squares). We then use this approach to assess whether simple models are reasonable
descriptors of the macroevolutionary dynamics of three important angiosperm
functional traits: specific leaf area, seed mass and leaf nitrogen content. We gathered
trait data from the literature and used a recently published angiosperm phylogeny to fit
models to subsets of the data. We demonstrate that there is tremendous variability in
the adequacy of simple models across groups, traits and time--scales. We argue that
the assessment of model adequacy should be a component of all comparative studies
and that our approach can be generally applied to this end.
%% Luke suggests I rework last line of abstract. Not sure how best to do this.


\vfill

\newpage



\begin{quotation}
\noindent There are known knowns; there are things we know we don't know. There are known unknowns; that is to say, there are things that we now know we don't know. But there are also unknown unknowns --- there are things we do not know we don't know.

---Fmr. U.S. Secretary of Defense Donald Rumsfeld
\end{quotation}

\section{Introduction}

Assessing model adequacy is a routine step in many statistical applications \citep{Gelmanbook}. Prior to drawing inferences from the parameters of a model, we want to know whether the model is appropriate for our data and our question. And not just whether it was the best of a set of candidates models, but whether it is a reasonable model in an absolute sense. While the importance of assessing the adequacy of a model is largely self--evident --- even the best of a set of bad models is still a bad model --- model adequacy has received relatively little consideration in phylogenetic comparative biology. Modern phylogenetic comparative methods (PCMs) are almost exclusively model--based (recently reviewed in \citep{Omeara2012, PennellHarmon}). By using such approaches our inferences are contingent on a model which adequately describes the pattern of trait evolution across the phylogeny. This is true whether we want to ask whether two traits are evolutionary correlated \citep{Felsenstein1985, Grafen1989, HarveyPagel1991}, what the general pattern of trait evolution has been through a group's history \citep{Mooers1999, Harmon2010, Hunt2012} or what features an ancestor may have had \citep{Schluter1997}. While many models for trait change and increasingly sophisticated methods for fitting them have been developed (e.g., \citep{Felsenstein1985, Hansen1997, Pagel1999, ButlerKing2004, Omeara2006, Eastman2011, Beaulieu2012}), we generally have very little idea as to whether the model we are using for a particular inference is adequate. What is worse, it is often not even given any consideration when PCMs are applied. To borrow Rumsfeld's taxonomy, model adequacy has largely been an ``unknown unknown''.

Modeling trait evolution along a phylogeny is a challenging task. The processes that have driven phenotypic evolution are almost certainly complex. Nonetheless, it may be the case that the pattern of phenotypic evolution can be captured by relatively simplistic models. Even if most of the details are missing, such models may be useful for quantiatively addressing macroevolutionary hypotheses. Brownian motion (BM) is the simplest, oldest, and most used, model of quantitative trait evolution in phylogenetic biology  \citep{Edwards1964, Felsenstein1973, Thompson1975, Felsenstein1985}. In a BM model, the variance of a trait across the phylogeny is assumed to accumulate linearly through time at some constant rate (usually denoted $\sigma^2$). Such a pattern may result from genetic drift \citep{Lande1977, Felsenstein1988, Lynch1990, HansenMartins1996}, randomly varying selection \citep{Felsenstein1973, Felsenstein1988} or else simply reflect the summation of many processes operating over macroevolutionary time \citep{HansenMartins1996, Uyeda2011, PennellPE}. Whatever, the mechanism, BM has proven to be an extremely useful model in comparative biology; it is the probabilistic model underlying Felsenstein's Independent Contrasts method \citep{Felsenstein1985} (see below) and is generally considered the null model against which all other models are compared.
 
Another model of quantitative trait evolution is the Ornstein--Uhlenbeck (OU) process \citep{Felsenstein1988, Hansen1997}. Under an OU model, variance accumulates at an instantaneous rate $\sigma^2$, but the traits are pulled towards an optimum $\theta$ with some strength $\alpha$. Given enough time, the OU process will result in a stationary distribution of trait values. This is mathematically equivalent to stabilizing selection on a quantitative trait within a population with constant genetic variance, population size, fitness optimum and strength of selection \citep{Lande1976}, though interpreting it as such is almost certainly incorrect \citep{HansenMartins1996, Hansen2012book, PennellHarmon}. 
 
Alternate models that have been considered include: the ``Early Burst'' (EB) \citep{Blomberg2003, Harmon2010} model, in which the rate of evolution declines exponentially through time; a BM model with a trend in the mean trait value \citep{Hunt2006} and other variations on the models described above (e.g., \citep{Pagel1997, Pagel1999, ButlerKing2004, Omeara2006, Eastman2011, Beaulieu2012, SlaterMEE}). 

Comparative biologists may use these models in a number of different ways \citep{Freckleton2011, PennellHarmon}. The fit of the model may be used directly to make inferences regarding the ``tempo and mode'' of trait evolution \citep{HansenMartins1996, Mooers1999, Harmon2010} or else may be used to make additional inferences, such as estimating the evolutionary correlation between traits \citep{Felsenstein1985, Grafen1989}. In either case, it is important to consider the adequacy of the model that is used. For example, if the ``true'' model of trait change resembles a multi--rate BM process (\textit{sensu} \citep{Omeara2006, Eastman2011}) but if we only consider BM and OU as alternative models, we might infer that an OU model is the best--fit, but would be completely misled regarding what processes were important in the evolution of the group. If we are testing for trait correlations, model inadequacy can artificially decrease the confidence intervals around the estimate of the relationship between the traits \citep{Rohlf2006}. 

The question of model adequacy is even more pertinent as the scale of comparative data continues to grow. Comparative analyses are increasingly being performed on very large datasets including thousands and even tens of thousands of species \citep{Coopermammal, Venditti2011, Jetz2012, Rabosky2013}. Though considering model adequacy is important at all scales, simple models are likely to inadequate as the number of taxa is increased. For example, while some simple  model of trait evolution, such as BM, may suffice for seed size across Oak species, it seems unlikely that this would be true across all Angiosperms \citep{Moles2005}.

There has been substantial investigation and discussion of model adequacy in the context of phylogenetic inference \citep{SullivanSwofford, Goldman, SandersonKim, Bollback2002, Ripplinger2010, Lewis2013, Reid2013}. Contrastly, in phylogenetic comparative biology, researchers are just starting to begin to think about ways to assess model adequacy, especially for models more complex that a simple BM process. We emphasize however, that despite the paucity of approaches, there has historically been a lot of discussion surrounding the appropriateness of various models for PCMs, particularly in the pioneering days of the field \citep{Felsenstein1985, Felsenstein1988, HarveyPagel1991, Garland1992, Pagel1993, Diaz1996, Price1997, Garland1999, GarlandIves2000, HansenOrzack2005, Hansen2012} and our own approach draws heavy inspiration from these earlier works.

Recently, two papers have developed simulation--based approaches to assessing the fit of models \citep{Boettiger2012, SlaterPennell}. Boettiger et al. \citep{Boettiger2012} proposed using the likelihood ratio as a test--statistic to determine if a given dataset is informative enough to distinguish between two models. Slater and Pennell \citep{SlaterPennell} developed a fully Bayesian posterior predictive simulation approach to detect if comparative data had the signature of an ``early burst'' of trait evolution \citep{FreckletonHarvey2006}. While their details differ, the aim of both of these papers is to assess whether a given dataset is informative enough to select amongst two candidate models. A broader question is whether a given model is a good fit to the data on its own terms --- that is, compared to the universe of possible models we might consider. Here we develop a approach to statistically evaluate absolute adequacy for models of continuous character evolution.

\section{A general framework for assessing model adequacy}
Our approach is based on the use of Felsenstein's \citep{Felsenstein1973, Felsenstein1985} Phylogenetic Independent Contrasts (PIC) method, which we will briefly review (for further details, see \citep{Felsenstein1985, Rohlf2001, Blomberg2012}). If we have observed trait values $X_1, X_2, \ldots, X_n$ at the tips of a phylogenetic tree $\mathcal{T}$ consisting of $n$ species. Due to shared history of ancestry between the tips, $X_1, X_2, \ldots, X_n$ are not independent observations. To deal with this problem, Felsenstein suggested computing the $n-1$ contrasts $c_1, c_2, \ldots, c_{n-1}$, the differences $X_{i} - X_{j}$ between the observed trait values of lineages $i$ and $j$. If we assume a BM model of trait evolution, in which variation accumulates directly proportional to time, these contrasts will be I.I.D. --- hence the name, ``Phylogenetic Independent Contrasts'' (or PICs). The procedure can be described algorithmically: 1) Take the contrast $c_k = X_i - X_j$ at node $k$, where $k$ is the most recent common ancestor of lineages $i$ and $j$; each contrast is associated with a node (that is $i$ and $j$ may be either tips or estimated internal states). 2) Standardize the contrast by its dividing by its standard deviation, which under BM is $\sqrt{v_i + v_j}$, the square root of the sum of the branch lengths $v$ leading to $i$ and $j$, 3) Estimate a trait value for the ancestral node $k$ by taking the mean of its descendants' trait values, weighted by their branch lengths

\begin{equation}
X_k = \frac{(1 / v_i)X_i + (1 / v_j)X_j}{1/v_i + 1/v_j}.
\end{equation}

4) Lengthen the branch below $k$ by $v_i v_j / (v_i + v_j)$, in order to account for error in the estimation of $k$. The branch lengths of the phylogeny will therefore be adjusted by this procedure; for clarity, we will denote the transformed branch lengths to be $v\prime$.

Iterating across all nodes in the phylogeny, the result is a set of contrasts $\mathbf{c}$, which, as stated above, will be I.I.D. if the model which generated the observations was BM \citep{Felsenstein1985, Rohlf2001}. As our method described in this paper essentially evaluates whether this condition holds, we will refer to $\mathbf{c}$ as contrasts, rather than ``PICs'' throughout. The basic principle of our approach is as follows. Given a set of $n$ observations, we can compute the $n-1$ contrasts. We calculate a set of summary statistics on the observed contrasts $\mathcal{S}_{obs}$. We then simulate $m$ datasets using a BM model of trait evolution, compute the contrasts on each data set and calculate the same summary statistics $\mathcal{S}_{sim}$. We then compare $\mathcal{S}_{obs}$ to $\mathcal{S}_{sim}$. If $\mathcal{S}_{i, obs}$ lies in the tails of $\mathcal{S}_{i, sim}$, the model does not adequately account for the variance in the axis encapsulated by $\mathcal{S}_i$.


\subsection*{Summary statistics}

To assess model adequacy we have chosen a set of six summary statistics $\mathcal{S} = \lbrace \mathcal{S}_1, \ldots, \mathcal{S}_6 \rbrace$

\begin{enumerate}
\item[$\mathcal{S}_1$] The mean of the squared contrasts. This is equivalent to the restricted maximum likelihood (REML) estimate of the Brownian motion rate parameter $\sigma^2$ \citep{Garland1992, Rohlf2001}. As $\mathcal{S}_1$ is a global rate estimate, we used this statistic to test whether the model is adequately capturing variance in rates.

\item[$\mathcal{S}_2$] The variance in the absolute value of the contrasts. Under a BM model with $\sigma^2 =$ 1, the expectation of $\mathcal{S}_2$ is 1. If the variance is greater than this, it suggests that we are not properly accounting for rate heterogeneity across the phylogeny.
%% We need a better way to distinguish (in English) what S1 and S2 are doing differently

\item[$\mathcal{S}_3$] The slope resulting from fitting a linear model between the absolute value of the contrasts and their expected variances, with the expected variances as the independent variable. Again, each (standardized) contrast has an expected variance proportional to $v\prime_i + v\prime_j$  \citep{Felsenstein1985}. Under a model of BM, we expect no relationship between the contrasts and their variances. In using $\mathcal{S}_3$, we are asking whether the contrasts are larger or smaller than we expect based on their branch lengths. If, for example, more evolution occured per unit time on short branches than long branches, we would observe a negative slope.

\item[$\mathcal{S}_4$] The slope resulting from fitting a linear model between the absolute value of the contrasts and the inferred ancestral state, with the inferred ancestral states as the independent variable. We estimated the ancestral state using the least--squared method suggested by \citep{Felsenstein1985} for the calculation of contrasts. We note that this is not technically an ancestral state reconstruction (it is more properly thought of as a weighted average value) and differs from more commonly applied approaches, such as the  maximum likelihood estimator \citep{Schluter1997}. We used this statistic to evaluate whether there is variation in rates relative to the trait value (e.g., do larger organisms evolve proportionally faster than smaller ones?)

\item[$\mathcal{S}_5$] The slope resulting from fitting a linear model between the absolute value of the contrasts and the height of the node at which they are inferred measured from the root, with the node height as the independent variable. For $\mathcal{S}_5$, we used the original node heights rather than the transformed node heights obtained from calculating the contrasts. This is used to capture variation relative to time and is alternatively known as the ``node--height test'' \citep{FreckletonHarvey2006} for detecting early bursts of trait evolution in putative adaptive radiations. It has been  previously used to assess the fit of BM models.

\item[$\mathcal{S}_6$] The D--statistic obtained from Kolmolgorov--Smirnov test from comparing the distribution of contrasts to that of a normal distribution with mean 0 and standard deviation $\sqrt{\overline{c^2}}$ --- the expected distribution of the contrasts under BM \citep{Felsenstein1985, Rohlf2001}. We chose this to capture deviations from normality. For example, if traits evolved via a ``jump--diffusion'' type process \citep{Landis2012}, in which there were occasional large ``jumps'' in phenotypic space \citep{PennellPE}, the tip data would no longer be multivariate normal owing to a few contrasts throughout the tree being much larger than the rest.  We used the empirically estimated standard deviation, rather than the expected (i.e., assuming $\sigma^2=$ 1) to make $\mathcal{S}_1$ and $\mathcal{S}_6$ less strongly dependent on one another.

\end{enumerate}

The three summary statistics fitting a linear model between the contrasts and some aspect of the data (i.e., $\mathcal{S}_3, \mathcal{S}_4, \mathcal{S}_5$) were developed by Garland and colleagues \citep{Garland1992, Garland1993,  Diaz1996} to test for adequacy of BM prior to performing PICs \citep{Felsenstein1985} or phylogenetic regression \citep{Grafen1989}. They have been used quite often in the comparative methods literature 

We have chosen these six summary statistics because they capture a range of dimensions of variability wherein the model may not be adequate. However, they are certainly not exhaustive. One could, for instance, calculate the median of the squared contrasts, the skew of the distribution of contrasts, etc. If the generating (i.e. true) model was known, we could use established procedures for selecting a set of sufficient (or, approximately sufficient \citep{MajoramJoyce}) summary statistics for that model. However, the aim of our project is to seek a set of summary statistics that capture violations of the assumption that the contrasts are I.I.D. and thus we do not have the generating model in hand. Our chosen statistics seek to capture a wide variety of model misspecifications but this does not mean that they will necessarily capture every type of model misspecification. Researchers interested in specific questions are encouraged to use alternate sets of summary statistics.

We also note that a model should be considered inadequate if it is rejected by any of the summary statistics that can be used. Furthermore, even if the model is not rejected by any of the summary statistics used, we still do not know if there adding another statistic would cause us to reject the model. The choice of how many summary statistics to use is ultimately one of balancing statistical intuition and computational effort and there is no good statistical theory to guide us as to which summary statistics to use and how many are enough \citep{Gelmanbook}.

\subsection*{Rescaling the phylogeny to construct a ``unit tree''}

We expect the contrasts to be I.I.D. when the model of trait evolution is BM but this is not necessarily true for alternative models; in other models the expectation for the summary statistics is no longer known. Our solution to the problem is to use the estimated parameters of a more complex model $\Theta$ to create what we term a ``unit tree''. A unit tree is defined as a tree in which if the model we fit is the true model, the data at the tips will be distributed as it would be under a BM process with a rate $\sigma^2$ equal to 1. Any phylogenetic tree $\mathcal{T}$ can be completely described by a $n \times n$ variance--covariance (vcv) matrix $\mathbf{C}$, where $n$ is equal to the number of tips in $\mathcal{T}$. The elements $C_{i,j}$ are the shared path--length from the root to the most recent common ancestor of $i$ and $j$. The diagonal elements ($i = j$) are simply the total distance from the root to the tips. For any model, we can describe a second matrix $\mathbf{\Sigma}$, which is the expected vcv matrix between observations at the tips under the model. For example, if we assume BM, in which variation accumulates proportionally to time under a single rate $\sigma^2$,
\begin{equation}
\Sigma_{ij} = \sigma^2 C_{ij}
\end{equation}
and thus
\begin{equation}
\mathbf{\Sigma} = \sigma^2 \mathbf{C}.
\end{equation}

For the OU model, 
\begin{equation}
\Sigma_{i,j} = \frac{\sigma^2}{2\alpha} e^{-2\alpha (T_{max} - C_{ij})} (1 - e^{-2\alpha C_{ij}})
\end{equation}

\citep{Hansen1997, ButlerKing2004}, where $T_{max}$ is the depth of $\mathcal{T}$.
We can similarily construct $\mathbf{\Sigma}$ based on whatever model we are interested in. The branch lengths of the phylogeny can then be rescaled ($\mathbf{C} \rightarrow \mathbf{C}^*$) according to their expected variances such that $\mathbf{C}^*=\mathbf{\Sigma}$. Such a transformation is valid for any model in which the trait values at the tips are assumed to be distributed according to a multivariate Gaussian distribution \citep{HoAne2013}, which is the case for almost all continuous trait models developed to date \citep{Omeara2012}. The result of this transformation is that if the $\Sigma$ is estimated using a model that adequately captures the variation in the trait, the contrasts will be distributed according to the standard normal distribution $\mathcal{N}(0,1)$. As such, we call the phylogeny described by $\mathbf{C}^*$ a ``unit tree''.

As stated above, a unit tree can be constructed from any multivariate Gaussian model such as multi--rate BM \citep{Omeara2006, Thomas2006, Eastman2011, Revell2012}, Pagel's $\lambda$, $\kappa$, and $\delta$ transformations \citep{Pagel1997, Pagel1999}, the AC/DC (also known as EB) model \citep{Blomberg2003, Harmon2010}, models with a directional trend \citep{Hunt2007} and and others. OU models can also be rescaled to form a unit tree; this is true of both multi--optimum \citep{ButlerKing2004} models and the more generalized form \citep{Beaulieu2012} in which the optimum, $\sigma^2$ and $\alpha$ values all vary across the tree \citep{HoAne2013}. For multi--optimum OU models, one we must rescale the trait values by subtracting the lineage--specific means according to the weight matrix \citep[see][]{Hansen1997, ButlerKing2004, Beaulieu2012, UyedaBayou}. The same rescaling technique can be used to assess the adequacy of the phylogenetic model used in regression models \citep{Grafen1989, Rohlf2001}; the difference being that for regression models, the contrasts of interest for assessing model adequacy are those computed on the residuals rather than the data (see Discussion).


\subsection{Assessing the adequacy of the model}
The final step in the analysis is to compare the observed to the simulated summary statistics. There are two alternative ways to conceptualize our approach. From a Bayesian perspective, our approach can be considered as a form of posterior predictive check (a.k.a. posterior predictive simulations) \citep{Rubin1984, Gelman1996}. In this case, we fit a model using Bayesian machinery (e.g., Markov chain Monte Carlo [MCMC] methods), then sample parameter values $\Theta$ from the joint posterior distribution $\Lambda$. For each $\Theta$ we construct a unit tree, compute the contrasts and calculate $\mathcal{S}_{obs}$. We simulate a dataset under BM with $\sigma^2 =$ 1 on the unit tree and similarily calculate $\mathcal{S}_{sim}$. Iterating across all of the samples we drew from $\Lambda$, we then obtain a distribution of summary statistics from both the observed and the simulated data. We can then compare these distributions and evaluate whether they are significantly different from one another. In this paper, we only compare the differences in means, but higher moments could also be considered. 

Alternatively, one can view our method from a frequentist perspective --- as such, our method can be construed as a form of parametric bootstrapping \citep{Efronbootstrap}. Rather than a distribution of observed summary statistics, we will get a point estimate of the summary statisitic computed on the unit tree constructed from the ML parameter estimates $\hat{\Theta}$ and a set of summary statistics from the simulated data, each dataset having been simulated on the same unit tree. A p--value can be estimated by evaluating where in the observed summary statistics lie in the distribution of simulated summary statistics. While the interpretation of the results are necessarily different under the two statistical paradigms, in practice, our approach works very much the same way in either case.

\section{Modeling the evolution of plant functional traits}

We use our approach to evaluate the ability of simple models to describe the evolution of functional traits in Angiosperms (flowering plants) at a number of different scales. We gathered data on three traits from the literature --- specific leaf area (SLA), seed mass and nitrogen content, all of which are commonly used proxies for functional variation, such as hydrodynamic cycling, life history, and photsynthetic capabilities, respectively \citep{Westoby2002}. We  matched these data to a recently published phylogeny \citep{Zanne2013}. Following \citep{Harmon2010}, we fit three simple models of trait evolution: BM, OU and EB to a large number of subclades, pulling out named and unnamed clades taken from time--slices across the tree. We then used our model adequacy approach to ask whether the best--fit model was actually a good fit in an absolute sense. (See Methods section for details on the analyses). 

\section{Results}

[RESULTS]

\section{Discussion}

Phylogenies are increasingly being recognized as essential data in evaluating macroevolutionary and macroecological hypotheses. However, as stated in the introduction, the phylogeny alone is not sufficient --- we also need a statistical model of trait evolution to describe the expected pattern of variation across the phylogeny. The patterns of trait evolution along a phylogeny has been shaped by numerous processes: selection and drift across an adaptive landscape; the dynamics of adaptive landscapes themselves; and potentially higher--level selection (i.e., species selection) on lineage--level traits \citep{PennellPE}. As biologists, we need to consider whether a given model allows us to gain insight into the evolutionary question of interest \citep{HansenOrzack2005, Hansen2012}. We also need to address the more statistical question of whether the model adequately captures the variation we are interested in. These two considerations --- biological and statistical --- must go hand--in--hand; a biologically informative model may be a poor fit to the data and a model that captures the variation in the data may not provide any biological insight \citep{Hansen2012}. In this paper, we focus on the statistical aspect of modeling trait evolution but emphasize that any model--fitting exercise is pointless unless guided by sound evolutionary thinking.

To date, comparative analyses have for the most part only considered a single model (such as BM) or else performed some sort of model comparison to select amongst a set of competing models. Whether or not the selected model is actually capturing the relevant patterns in the data --- that is, whether the model is adequate in the absolute sense -- has been largely overlooked and this may have very serious consequences for any inferences drawn from these analyses. Here we present a general framework for assessing the adequacy of phylogenetic models of continuous characters. Our approach can apply to any model in which the traits at the tips of the phylogeny are assumed to come from a multivariate normal distribution. Mechanically, our method is rather simple but we believe that it can be extremely useful for future analyses of comparative data. We argue that all phylogenetic comparative analyses should include a model--checking component; doing so will help ensure that the inferences obtained from them are reliable.

As we demonstate in our analysis of the evolution of plant functional traits, the simple models often used in comparative biology are often inadequate and woefully so at large scales. Our results should give researchers cause for serious concern. Though phylogenetic comparative analyses have been widely performed throughout the literature, there has not been any method for validating the model used. Our results suggest that many previous comparative analyses may need to be re--evaluated in light of model adequacy. The very tight scaling of model (in)adequacy with tree size suggests that concerns about model adequacy are especially pertinent when analyses are conducted on large phylogenies. Of course no biologist is likely to be shocked by our findings; indeed, one of the main reasons we are interested in studying macroevolutionary diversity is the complexity of the processes that may have generated it.  

\subsection{Model adequacy for angiosperm functional traits}
Major patterns we found.

\subsection*{A case study in model adequacy --- seed size evolution in the Meliaceae \& the Fagaceae}
%% NEED TO WORK ON THIS SECTION
%% USE BOTH BAYESIAN AND ML


\subsection*{Why models may be inadequate}
There are a number of likely interacting causes for model inadequacy. The most biologically interesting of these is that the evolutionary processes in some group are more complex (or just different) from the processes and patterns accounted for by our model.  There is substantial evidence from both phylogenetic comparative and paleobiological data than the patterns of evolution are often quite complex, with different processes and different rates occuring across the phylogenies of many groups \citep{Foote1997, Grey2008, Hunt2012, Hopkins2012, PennellPE}. It is likely that phylogenetic models of trait evolution which do not accomodate such variation are inadequate. In our analyses of plant functional trait evolution, we used only simple models of trait evolution. It is undoubtedly true that at the larger scales (and often at smaller ones), a single rate or single--optimum model is likely to be woefully inadequate for traits like seedmass \citep{Moles2005}. Thus, far from a nuisance, assessing model adequacy may tell us interesting things about the biology of a group which would not be apparent from solely comparing relative fits of a limited set of candidate models. There has been a lot of progress recently in the developement of more sophisticated and parameterized models of trait evolution \citep{ButlerKing2004, Omeara2006, FitzJohn2010, Eastman2011, Venditti2011, Revell2012, Beaulieu2012}. Our approach can help researchers decide when it is necessary to invoke further complexity. Importantly, knowing which summary statistics reject a model can provide insight into what type of complexity (i.e. heterogeneity in rates and/or models) is necessarily to include in order adequately capture the variation in the trait.

Model misspecification is not the only source of error when fitting trait models. Estimating parameters, especially under likelihood, is often non--trivial owing to identifiability issues in some regions of parameter space \citep{Ane2008, HoAne2012}. This issue is generally underexplored but is likely to important, especially for more parameter--rich models. The construction of the unit tree depends on the parameter estimates and our measure of model adequacy will therefore be influenced by their mis--estimation. Second, measurement error may have pathological effects regarding model adequacy and the effects may vary depending on the model used \citep{PennellPE}. In our empirical analyses we used a global estimate of standard error. Ideally, we would have used observations from individuals and estimated the error along with the model \citep{Ives2007, Felsenstein2008,  Hansen2012}, but this type of data was not available for many taxa in our datasets. 

Phylogenetic misestimation may also have an effect on the adequacy of a model. All of the statistical models of trait evolution assume that branch lengths are estimated without error, though in practice this is never actually the case. The influence of branch length error in PCMs is not really known and its effect will depend on whether the error is random or systematically biased. Misestimating topology may have very serious consequences for model adequacy in some types of analysis. For example, if species are paired with the incorrect species, traits of sister species may appear to be more dissimilar than they really are, leading to inflated contrasts and rate estimation close to the tips. In our empirical example, the ML tree we used (from \citep{Zanne2013}) is likely to have substantial topological errors owing to the scale of the data and the analytical shortcuts inherent in building a ``megaphylogeny'' \citep{Smith2009}. The error in the topology (which is especially large towards the tips) may be a a major contributor to the inadequacy of the simple models across the functional trait datasets. 
A model can be inadequate as a result of any of these and it is often challenging to distinguish the contribution of these in real datasets. Our approach cannot provide a clear reason why a model is inadequate, only indicate that it is.

\subsection*{An adequate model does not necessarily mean a good model}
Simply because a model cannot be rejected with our approach does not necessarily mean that the model itself is a good one. First one must consider whether there is enough statistical power to reject a model. The more contrasts in a dataset (i.e. the more taxa), the more power there is to detect deviances from the expected distribution. We observed a strong positive correlation between a multivariate measure of model (in)adequacy and the number of taxa in a group (see above, figure XX). While as we argue above, it is likely that the pattern of evolution is increasingly complex at larger scales, it is also possible that the simple models we used were on average equally inadequate at all scales and we simply had more power to detect this on larger trees. This explanation is supported by the fact that there is little correlation between the age of the clade and the adequacy of the model (see supp fig). The power to reject a given model is inversely related to the ability to find support for a model, using some form of model selection.

Both the original model fit and the simulations are both based on the observed tip values. These may or may not be representative of the states that have occured throughout the clade's history. In other words, a model may adequately capture variation in our observed tip values but may be misleading when making inferences about the evolutionary history of the trait. Incorporating fossil taxa has been shown to dramatically alter the estimated model parameters and the evolutionary inferences \citep{FF2006, Slater2012Fossil, SlaterMEE}. Likewise, if contemporary species are sampled in a non--random way, such that some trait values are over-- or under--represented \citep{Freckletoninaction}, the model may explain the data but the inferences from the model may be misled. 

\subsection*{Extensions of this approach}
The framework we present here can be extended in number of ways. First, we have only considered a limited set of summary statistics. We chose them because each of these has a clear statistical expectation and observed deviations from them have intuitive explanations. However, they are certainly a subset of all possible summary statistics that could be applied. One thing we did not consider, for example, is autocorrelation between neighboring contrasts \citep{Gittleman1990}. One could also potentially use alternative forms of the contrasts, such as contrasts considering within species variation \citep{Felsenstein2008}, or alternative ways of assessing the summary statistics, such as using robust regression in lieu of fitting standard linear models for the 3 summary statistics involving slope ($\mathcal{S}_3, \mathcal{S}_4, \mathcal{S}_5$) (see \citep{SlaterPennell}). There are undoubtedly more such summary statistics that creative researchers could potentially conceive of; some will be more appropriate than others for different questions.

The method we have described here can apply to any model of trait evolution which can be described by a multivariate normal distribution. That is, where the original tree can be transformed from the model fitted parameters to a unit tree. Our approach can therefore not be applied to other types of models, such as those which assume a fat--tailed distribution of trait change \citep{Landis2012} or state--dependent diversification models \citep{Bokma2008, FitzJohn2010}. Our approach is also not applicable to models of discrete character evolution, such as the Mk model \citep{Pagel1994} and other variants \citep{Felsenstein2012, Beaulieu2013}. However, for these types of traits, approaches that have been developed to the adequacy of sequence evolution models \citep{Bollback2002, Lewis2013} could potentially be employed. Developing and implementing such methods for discrete character models is an important area for future research as model adequacy is just as pertinent a consideration as for the continuous case \citep{ReadNee1995}. 

Another possibility which our approach suggests is that researchers could potentially use the summary statistics as a means to perform question--specific model selection. This is the essence of the ``node--height'' test for detecting early bursts of trait evolution \citep{FreckletonHarvey2006}. Slater and Pennell \citep{SlaterPennell} developed a fully Bayesian posterior predictive method for detecting such early bursts from comparative data. For some problem, one may be care a lot about whether the model is capturing the variance in some axis (or axes) and be less concerned about others. One could then use posterior predictive simulations and a well--chosen set of summary statistics to help guide model selection \citep{Bollback2002, Lewis2013}. One could also potentially use summary statistics to construct cost functions and select amongst models in a decision--theoretic framework \citep{Robert2007}. Such an approach has proven to be very useful in selecting between models of sequence evolution \citep{Minin2003, SullivanJoyce2005} but has not been previously considered in comparative methods.

\subsection{Concluding remarks}
While we describe this as a novel approach, much of it stems directly from earlier work in the field. In the 1980s and 1990s --- the time when phylogenetic comparative biology was just starting to emerge as a discipline --- much discussion surrounded the appropriateness of various methods and models \citep{Felsenstein1985, Felsenstein1988, HarveyPagel1991, Garland1992, Pagel1993, Diaz1996, Price1997, Garland1999, GarlandIves2000}. However, as phylogenetic approaches have become more widely accepted and applied in a wider variety of fields, including community ecology \citep{Webb2002, CB2009}, paleobiology \citep{Hunt2012}, genomics \citep{Brawand2011}, etc., much of this debate has seemingly been largely forgotten (but see \citep{Losos2011, Hansen2012} for recent discussions). As the scale of phylogenetic comparative data has grown, these concerns regarding model adequacy are more important than ever. We argue that evaluating the fit of macroevolutionary models ought to be an important component of any comparative analysis. The approach we develop in this paper can generally be applied to a variety of continuous trait models. Alternative approaches that can apply to discrete models (binary, multistate and ordinal) as well as continuous trait models which are not multivariate normal are needed. 

There is much fertile ground to explore regarding how best to think about modeling trait evolution. The recent growth in comparative methods is extremely exciting. However, we would argue that it is still not clear how best to analyze comparative data and model trait evolution, especially when considering evolutionary patterns and process across large scales. One thing that we think will be essential is a serious consideration of when our models are appropriate. In this paper we focused on statistical considerations but we emphasize that even a statistically adequate model may not be appropriate for a given biological question \citep{Hansen2012}. We hope that our approach can help move statistical model adequacy from being an ``unknown unknown''  to being a ``known known'' or at least a ``known unknown'' --- that is to say, we may not know exactly why our model is not capturing the variation in the data, but at least we will know it is not.

\section{Materials and Methods}

\subsection{Phylogeny and Data}
We used a phylogeny of Angiosperms from a recent study by \citet{Zanne2013}. The tree contains xx,xxx Angiosperm taxa and covers xx \% of familial diversity and yy \% of generic diversity across all Angiosperms. We will not provide the details on the phylogeny here and refer interested readers to the original publication \citep{Zanne2013}. For the purposes of this study, we used the MLE point estimate of the phylogeny. We could have used a set of bootstrapped trees and ran our analyses across all of them, but for our purposes, it will likely not qualitatively affect our results. This tree is published in \textsc{dryad} (accession number).

We used large datasets on three functionally important plant traits: specific leaf area, leaf nitrogen content, and seed mass.  All data are available via the internet (see Supplemental Material for specific locations and scripts to access and process the original data; due to the licensing of the datasets, they could not be published in a complete form with this manuscript). The specific leaf area (SLA) and leaf nitrogen data comes from Wright et al. \citep{Wright2004} with additional SLA data from the LEDA project \citep{Kleyer2008}. Seed mass data comes Kew \citep{Kew2008}.  Geometric species means were used for all three traits.  The full data set includes 3369 species for SLA of which XX correspond to species in the Zanne et al. \citep{Zanne2013} tree.  The sample size for leaf N is XX and YY; for seed mass it is ZZ and FF.  

%% NEED TO ADD MORE DETAILS ON HOW SE WAS OBTAINED
To (partially) account for measurement error, we estimated the standard error (SE) for each of the three traits doing [something here]. For practical purposes, we assumed that the SE was constant across the phylogeny as we only had within--species sampling for a subset of the taxa. This assumption is likely unwarranted but even a somewhat inaccurate estimate of measurement error is better than not assuming any measurement error at all \citep{Hansen2012}.

\subsection{Analysis}

We first matched our trait data to the Angiosperm phylogeny from \citet{Zanne2013} and then extraced subclades from this dataset in a few ways: by pulling out family--level and order--level phylogenies and by time slicing the tree at 50 my intervals and extracting any (named or unnamed) clades for which the most recent common ancestor of a group was younger than the timeslice. (In the ML tree, the crown age of Angiosperms is estimated to be yyy my.) We kept only subclades for which there was at least 20 species that occured in both the phylogeny and trait data so that we had a reasonable ability to estimate model parameters and distinguish between models. For SLA, this left us with AA clades, seed mass BB clades and leaf nitrogen content CC clades. We will note that these are of course non--independent, many of the same taxa were included in family, order and time--slice subtrees. 

Following Harmon et al. \citep{Harmon2010}, we focused the analysis on a few simple models of trait evolution for the univariate case --- BM, OU and EB. While we predict \textit{a priori} that these models are likely to be poor in some cases (especially at larger scales), we chose these models because they allowed us to intuitively compare the adequacy of models across datasets. As the purpose of the empirical analyses was to examine the consequences of considering model adequacy rather than to comprehensively characterize the evolutionary patterns of these traits, we thought that simple models were most appropriate.

For each subtree and each trait, we performed two sets of analyses: one Bayesian, the other using maximum likelihood. For the Bayesian analysis, we fit the three models (BM, OU and EB) using a MCMC approach, sampling paramter values using the slice sampling method \citep{Nealslice}, as implemented in the \texttt{R} package \texttt{diversitree} \citep{FitzJohn2012}. For the BM model we set a broad uniform prior on $\sigma^2 \sim \mathcal{U}[0, 5]$, the upper bound being substantially larger than the ML estimate of $\sigma^2$ for any clade. For the OU model, we used the same prior for $\sigma^2$ and drew $\alpha$ values from a Half--Cauchy distribution with a $\gamma$ parameter of 25; the latter distribution is a commonly used weakly--informative prior for scale parameters in a variety of statistical applications \citep{Gelmanprior, Polson2012}. A complication involved in fitting OU models is deciding what assumptions to make about the state at the root ($z_0$). Harmon et al. \citep{Harmon2010} stated that the ML estimate of $z_0$ is equal to that of $\theta$; however this statement is not correct as $\theta$ and $z_0$ can diverge under some conditions. But as allowing $\theta$ and $z_0$ to be estimated separately can lead to serious problems of identifiability \citep{HoAne2012}, we follow other authors \citep{Labra2009, Beaulieu2012} and assume that $z_0$ is at the optimum. For the EB model, we again used the same prior for $\sigma^2$ and a uniform prior on $a$, the exponential rate of decrease in $\sigma^2$, such that $a \sim \mathcal{U}[\log (10^{-5})/T_{max}, 0]$ where again, $T_{max}$ is the depth of the tree \citep{SlaterPennell}.

We ran each Markov chain for 10,000 generations, which preliminary investigated demonstrated was more than sufficient to obtain convergence and proper mixing for these simple models. After removing a burn--in of 1000 generations, we compared the models using the Deviance Information Criterion (DIC) \citep{dic} and selected the best--fitting model for further analyses; if there was a tie, we simply selected one of the best--fit at random. While model selection is of course an important and difficult problem in general, we argue that it does not matter a great deal for our purposes. If two models have similar support, the transformed tree based on the respective parameters of the models, will be very much the same and the adequacy results will not differ substantially. For the best--fitting model, we drew 1000 samples from the joint posterior distribution (again, after removing burn--in). For each of the sampled parameter sets, we used the parameter values to construct a unit tree and calculated our six summary statistics on the contrasts. We then simulated a dataset on the same unit tree and calculated the summary statistics on the contrasts of the simulated data.
 
For the ML analysis, we repeated the same general procedure but fit the models using ML with the \texttt{geiger} \citep{geiger} package. We compared the fit of the models using AIC \citep{Akaike1974} and again ran the adequacy analysis on the best--fit model. In this case because we only created the unit tree once based on the ML parameter estimates, we simulated 1000 datasets on this unit tree. 

For both types of analyses, we computed a p--value by comparing our observed summary statistics (distribution or point estimate) to the distribution of simulated summary statistics. As a multivariate measure of model adequacy, we calculated the mean Mahalanobis distance, a scale--invariant distance between the observed summary statistics and the mean of our simulated summary statistics, taking into account the covariance structure between the summary statistics.

\subsection{A note on implementation}

The method described here has been implemented in an \texttt{R} package \texttt{arbutus}. It is available on CRAN and at \texttt{www.github.com/mwpennell/arbutus}. For this project, we have also adopted code from the \texttt{ape} \citep{ape}, \texttt{geiger} \citep{geiger}, \texttt{diversitree} \citep{FitzJohn2012} and \texttt{ggplot2} \citep{ggplot2} libraries. We have written functions to parse the output of a number of different programs for fitting trait evolution models (see \ref{supp-table-fxns}). As this approach was developed to be general, we have written the code in such a way that users can include their own summary statistics and trait models in the analyses; we include demonstrations of how this can be done in the supplementary material.

\section{Acknowledgments}
We would like to thank the members of the Tempo and Mode of Trait Evolution Working Group at the National Evolutionary Synthesis Center (NESCent) as well as NESCent for funding our group. Josef Uyeda, Paul Joyce, Daniel Caetano and Graham Slater also provided insightful comments on this project.

\newpage
\bibliographystyle{plos}
\bibliography{model_ad.bib}

\end{document}


